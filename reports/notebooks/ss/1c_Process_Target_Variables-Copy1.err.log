Traceback (most recent call last):
  File "/home/danbot/code/data_analysis/lib/python3.12/site-packages/jupyter_core/utils/__init__.py", line 154, in wrapped
    asyncio.get_running_loop()
RuntimeError: no running event loop

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/danbot/code/data_analysis/lib/python3.12/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/home/danbot/code/data_analysis/lib/python3.12/site-packages/nbclient/client.py", line 1319, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/danbot/code/data_analysis/lib/python3.12/site-packages/jupyter_core/utils/__init__.py", line 158, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/base_events.py", line 687, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/home/danbot/code/data_analysis/lib/python3.12/site-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "/home/danbot/code/data_analysis/lib/python3.12/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/home/danbot/code/data_analysis/lib/python3.12/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
test_stn = '05010500'
test_df = dpf.get_timeseries_data(test_stn)

test_fig = figure(title=f'Sample Distribution by Dictionary Size (Station ID {test_stn})',
                 width=800, height=300)
n = 0
bitrates_even = [4, 6, 8, 10, 12]
for b in bitrates_even:
    test_df, linear_edges, log_edges = quantize_signal(test_df, b, f'{b}_bits_quantized', test_stn)
    unique, counts = np.unique(test_df[f'{b}_bits_quantized'], return_counts=True)
    count_dict = {k: 1/v for k, v in zip(unique, counts)}
    frequencies = [count_dict[e] if e in count_dict else 0 for e in range(1, 2**b)]
    normed_frequencies = frequencies / sum(frequencies)
    H = entropy(normed_frequencies, base=2)
    bin_midpoints = (linear_edges[1:] + linear_edges[-1]) / 2
    bottoms = [0 for _ in normed_frequencies]
    test_fig.quad(left=linear_edges[:-1], right=linear_edges[1:], top=normed_frequencies, bottom=bottoms, 
                  legend_label=f'{b} bits (H={H:.2f})', color=Sunset10[n], fill_alpha=0.5)
    
    test_fig.xaxis.axis_label = r'$$\text{Flow} \left[ m^3/s \right]$$'
    test_fig.yaxis.axis_label = r'P(X)'
    test_fig.legend.location = 'top_left'
    test_fig.legend.click_policy = 'hide'
    n += 2
    

------------------


[31m---------------------------------------------------------------------------[39m
[31mNameError[39m                                 Traceback (most recent call last)
[36mCell[39m[36m [39m[32mIn[3][39m[32m, line 2[39m
[32m      1[39m test_stn = [33m'[39m[33m05010500[39m[33m'[39m
[32m----> [39m[32m2[39m test_df = [43mdpf[49m[43m.[49m[43mget_timeseries_data[49m[43m([49m[43mtest_stn[49m[43m)[49m
[32m      4[39m test_fig = figure(title=[33mf[39m[33m'[39m[33mSample Distribution by Dictionary Size (Station ID [39m[38;5;132;01m{[39;00mtest_stn[38;5;132;01m}[39;00m[33m)[39m[33m'[39m,
[32m      5[39m                  width=[32m800[39m, height=[32m300[39m)
[32m      6[39m n = [32m0[39m

[36mFile [39m[32m~/code/distribution_estimation/docs/notebooks/ss/data_processing_functions.py:340[39m, in [36mget_timeseries_data[39m[34m(official_id, min_flow, try_counter)[39m
[32m    302[39m [38;5;28;01mdef[39;00m[38;5;250m [39m[34mget_timeseries_data[39m(official_id, min_flow=[32m1e-4[39m, try_counter=[32m0[39m):
[32m    303[39m [38;5;250m    [39m[33;03m"""[39;00m
[32m    304[39m [33;03m    Imports streamflow data for a given station ID, processes it to handle low flow values,[39;00m
[32m    305[39m [33;03m    and returns the processed DataFrame.[39;00m
[32m   (...)[39m[32m    338[39m [33;03m    4  2020-01-05  0.0001                      True[39;00m
[32m    339[39m [33;03m    """[39;00m
[32m--> [39m[32m340[39m     files = [e [38;5;28;01mfor[39;00m e [38;5;129;01min[39;00m [43mSTREAMFLOW_FILES[49m [38;5;28;01mif[39;00m e.endswith([33mf[39m[33m'[39m[38;5;132;01m{[39;00mofficial_id[38;5;132;01m}[39;00m[33m.csv[39m[33m'[39m)]
[32m    341[39m     [38;5;28;01mif[39;00m [38;5;28mlen[39m(files) == [32m2[39m:
[32m    342[39m         [38;5;66;03m# If there is more than one match, look for an exact string match.[39;00m
[32m    343[39m         files = [e [38;5;28;01mfor[39;00m e [38;5;129;01min[39;00m files [38;5;28;01mif[39;00m e == [33mf[39m[33m'[39m[38;5;132;01m{[39;00mofficial_id[38;5;132;01m}[39;00m[33m.csv[39m[33m'[39m]  

[31mNameError[39m: name 'STREAMFLOW_FILES' is not defined

