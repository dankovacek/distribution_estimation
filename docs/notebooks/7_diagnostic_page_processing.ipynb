{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f97393",
   "metadata": {},
   "source": [
    "### Generate Diagnostic Pages \n",
    "\n",
    "In this section:\n",
    "\n",
    "1. We assemble prediction outputs, performance metrics, and metadata needed to generate station-level diagnostic pages.\n",
    "\n",
    "2. We structure these data into standardized formats for plotting flow duration curves, prediction–observation comparisons, and model-specific diagnostics.\n",
    "\n",
    "3. We create and export visual summaries for each catchment, highlighting where models align, where they diverge, and how these patterns relate to observed streamflow behaviour.\n",
    "\n",
    "4. We prepare these diagnostic products for inclusion in the broader reporting framework and for use in station-level interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558cd32f-b562-4502-ab63-826aede8f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# import geopandas as gpd\n",
    "# from shapely.geometry import Point\n",
    "import math\n",
    "import xyzservices.providers as xyz\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "from bokeh.plotting import figure, show, output_file, save\n",
    "from bokeh.layouts import gridplot, row, column\n",
    "from utils.fdc_estimator_context import FDCEstimationContext\n",
    "# from utils.knn_estimator import kNNEstimator\n",
    "from utils.kde_estimator import KDEEstimator\n",
    "from utils.fdc_data import StationData\n",
    "from utils.evaluation_metrics import EvaluationMetrics\n",
    "\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import Div\n",
    "\n",
    "import utils.data_processing_functions as dpf\n",
    "\n",
    "import xyzservices.providers as xyz\n",
    "tiles = xyz['USGS']['USTopo']\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9525e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(os.getcwd())\n",
    "\n",
    "from utils.table_notes import notes_html\n",
    "attr_fpath = 'data/BCUB_watershed_attributes_updated_20250227.csv'\n",
    "attr_df = pd.read_csv(attr_fpath, dtype={'Official_ID': str})\n",
    "station_ids = sorted(attr_df['official_id'].unique().tolist())\n",
    "\n",
    "# streamflow folder from (updated) HYSETS\n",
    "HYSETS_DIR = Path('/home/danbot/code/common_data/HYSETS')\n",
    "hs_df = pd.read_csv('data/HYSETS_watershed_properties.txt', sep=';')\n",
    "hs_df = hs_df[hs_df['Official_ID'].isin(station_ids)]\n",
    "hs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1356ccc6-3d6d-4e08-bdbc-53a798187d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve LSTM ensemble predictions\n",
    "lstm_result_base_folder = Path('/home/danbot/code/neuralhydrology/data/')\n",
    "results_revisions = ['20250514', '20250627']\n",
    "lstm_result_files = os.listdir(lstm_result_base_folder / f'ensemble_results_{results_revisions[0]}')\n",
    "lstm_result_stns = [e.split('_')[0] for e in lstm_result_files]\n",
    "\n",
    "# filter for the common stations between BCUB region and LSTM-compatible (i.e. 1980-)\n",
    "daymet_concurrent_stations = list(set(station_ids) & set(lstm_result_stns))\n",
    "# assert '012414900' in daymet_concurrent_stations\n",
    "print(f'There are {len(daymet_concurrent_stations)} monitored basins concurrent with LSTM ensemble results.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f016b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see notebook 1 for details on how these were identified\n",
    "exclude_stations = ['08FA009', '08GA037', '08NC003', '12052500', '12090480', '12107950', '12108450', '12119300', \n",
    "                    '12119450', '12200684', '12200762', '12203000', '12409500', '15056070', '15081510',\n",
    "                    '12323760', '12143700', '12143900', '12398000', '12058800', '12137800', '12100000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c026ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_id_dict = {row['Watershed_ID']: row['Official_ID'] for _, row in hs_df.iterrows()}\n",
    "# and the inverse\n",
    "official_id_dict = {row['Official_ID']: row['Watershed_ID'] for _, row in hs_df.iterrows()}\n",
    "# also for drainage areas\n",
    "da_dict = {row['Official_ID']: row['Drainage_Area_km2'] for _, row in hs_df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e37ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization_type = 'discrete'\n",
    "bitrate = 8\n",
    "\n",
    "baseline_folder = BASE_DIR / 'data' / 'baseline_distributions' / f'{bitrate:02d}_bits'\n",
    "fname = f'pmf_obs.csv'\n",
    "if regularization_type == 'kde':\n",
    "    print('Using KDE regularization for PMF estimation.')\n",
    "    fname = 'pmf_kde.csv'\n",
    "\n",
    "pmf_path = baseline_folder / fname\n",
    "pmf_obs_df = pd.read_csv(pmf_path)\n",
    "daymet_concurrent_stations = [s for s in daymet_concurrent_stations if s not in exclude_stations and s in pmf_obs_df.columns]\n",
    "print(f'There are {len(daymet_concurrent_stations)} monitored basins concurrent with LSTM ensemble results.')\n",
    "\n",
    "# log_edges = np.concatenate([pmf_obs_df['left_log_edges'].values[:1], pmf_obs_df['right_log_edges'].values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a4e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_and_filter_hysets_data(station_ids, hs_df):\n",
    "#     hs_df = hs_df[hs_df['Official_ID'].isin(station_ids)]\n",
    "\n",
    "#     # load the updated HYSETS data\n",
    "#     updated_filename = 'HYSETS_2023_update_QC_stations.nc'\n",
    "#     ds = xr.open_dataset(HYSETS_DIR / updated_filename)\n",
    "\n",
    "#     # Get valid IDs as a NumPy array\n",
    "#     selected_ids = hs_df['Watershed_ID'].values\n",
    "\n",
    "#     # Get boolean index where watershedID in selected_set\n",
    "#     # safely access watershedID as a variable first\n",
    "#     ws_ids = ds['watershedID'].data  # or .values if you prefer\n",
    "#     mask = np.isin(ws_ids, selected_ids)\n",
    "\n",
    "#     # Apply mask to data\n",
    "#     ds = ds.sel(watershed=mask)\n",
    "#     # Step 1: Promote 'watershedID' to a coordinate on the 'watershed' dimension\n",
    "#     ds = ds.assign_coords(watershedID=(\"watershed\", ds[\"watershedID\"].data))\n",
    "\n",
    "#     # Step 2: Set 'watershedID' as the index for the 'watershed' dimension\n",
    "#     return ds.set_index(watershed=\"watershedID\")\n",
    "\n",
    "\n",
    "# ds = load_and_filter_hysets_data(station_ids, hs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfb687e-91f2-4065-8900-bd43b1d9d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_knn_label_col(df):\n",
    "    # Split the string column\n",
    "    # Determine format based on length\n",
    "    split_labels = df['Label'].str.split('_')\n",
    "    df['n_parts'] = split_labels.str.len()\n",
    "\n",
    "    assert len(set(df['n_parts'])) == 1, \"Not all labels have the same number of parts\"\n",
    "\n",
    "    # Define expected column structures\n",
    "    # format_a_cols = [\"Official_ID\", \"k\", \"NN\", 'concurrent', 'tree_type', 'dist', 'weighting', 'ensemble_method']\n",
    "    format_cols = [\"Official_ID\", \"k\", \"NN\", 'tree_type', 'dist', 'ensemble_weight', 'ensemble_method']\n",
    "\n",
    "    # Subset by format\n",
    "    df_a = df[df['n_parts'] == len(format_cols)].copy()\n",
    "\n",
    "    # Split and join with suffix to avoid conflicts\n",
    "    df_a_split = df_a['Label'].str.split('_', expand=True)\n",
    "    df_a_split.columns = format_cols\n",
    "    merged = pd.concat([df_a.reset_index(drop=True), df_a_split.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # Drop duplicates (if any) and update\n",
    "    merged.drop(columns=['NN', 'dist', 'n_parts', 'minYears', 'minOverlapPct'], errors='ignore', inplace=True)\n",
    "    merged = merged.loc[:, ~merged.columns.duplicated()]\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3af379-ae22-464e-a816-8d959d69a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve LSTM ensemble predictions\n",
    "LSTM_ensemble_result_folder = '/home/danbot/code/neuralhydrology/data/ensemble_results_20250514'# uses NSE mean as loss function\n",
    "# LSTM_ensemble_result_folder = '/home/danbot/code/neuralhydrology/data/ensemble_results_20250627'# uses NSE 95% as loss function\n",
    "lstm_result_files = os.listdir(LSTM_ensemble_result_folder)\n",
    "lstm_result_stns = [e.split('_')[0] for e in lstm_result_files]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcfd8a6",
   "metadata": {},
   "source": [
    "### Compute the NSE on the daily timeseries for evaluation over the sample\n",
    "\n",
    "Compute the distribution of NSE values for the LSTM ensembles to report as a benchmark in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10383870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_NSE_for_lstm(obs, sim):\n",
    "    mean_observed = np.mean(obs)\n",
    "    numerator = np.sum((obs - sim) ** 2)\n",
    "    denominator = np.sum((obs - mean_observed) ** 2)\n",
    "    nse = 1 - (numerator / denominator)\n",
    "    return nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3123a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "NSE_vals = []\n",
    "for f in lstm_result_files:\n",
    "    stn = f.split('_')[0]\n",
    "    if stn in exclude_stations:\n",
    "        continue\n",
    "    ldf = pd.read_csv(Path(LSTM_ensemble_result_folder) / f)\n",
    "    # compute the ensemble mean time sieres\n",
    "    ldf['qsim_mean'] = ldf[[c for c in ldf.columns if '_sim_' in c]].mean(axis=1)\n",
    "    ldf.dropna(subset=['streamflow_obs', 'qsim_mean'], inplace=True)\n",
    "    # compute the NSE on the daily timeseries\n",
    "    nse = compute_NSE_for_lstm(ldf['streamflow_obs'].values, ldf['qsim_mean'].values)\n",
    "    NSE_vals.append(nse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817e08ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of NSE values with bokeh\n",
    "p = figure(title='Distribution of NSE values for LSTM ensemble', \n",
    "           x_axis_label='NSE', y_axis_label='Frequency', \n",
    "           width=600, height=400)\n",
    "# compute the empirical cdf\n",
    "x = np.sort(NSE_vals)\n",
    "assert np.all(np.isfinite(x))\n",
    "y = np.arange(1, len(x) + 1) / len(x)\n",
    "p.line(x, y, line_width=2, color='dodgerblue', legend_label='LSTM Ensemble')\n",
    "# show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1251a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nse, median_nse, ci_nse = np.mean(NSE_vals), np.median(NSE_vals), (np.percentile(NSE_vals, 2.5), np.percentile(NSE_vals, 97.5))\n",
    "n_failures = np.sum(np.array(NSE_vals) <= 0)\n",
    "pct_failures = n_failures / len(NSE_vals) * 100\n",
    "print(f'Mean NSE: {mean_nse:.2f}, Median NSE: {median_nse:.2f}, 95% CI: ({ci_nse[0]:.2f}, {ci_nse[1]:.2f}), % Failures: {n_failures}/{len(NSE_vals)} {pct_failures:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c4b12-832e-4481-886b-558db49922c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dfs = {}\n",
    "lstm_rev_date = LSTM_ensemble_result_folder.split('_')[-1]\n",
    "sub_folder = f'lstm_{lstm_rev_date}'\n",
    "# results_folder = '/media/danbot/Samsung_T5/fdc_estimation_results/'\n",
    "results_folder = f'data/results/fdc_estimation_results_{bitrate:02d}_bits'\n",
    "if regularization_type == 'kde':\n",
    "    results_folder = f'data/results/fdc_estimation_results_kde'\n",
    "    \n",
    "completed_stns = [c.split('_')[0] for c in os.listdir(os.path.join(results_folder, sub_folder))]\n",
    "print(f'Found {len(set(completed_stns))} completed stations in {sub_folder} results folder.')\n",
    "\n",
    "for method in ['parametric', 'lstm', 'knn']:\n",
    "    print(f'   Loading {method} results')\n",
    "    method_results_fpath = os.path.join('data', 'results', 'additional_results', f'{method}_all_results_{bitrate:02d}_bits.csv')\n",
    "    if regularization_type == 'kde':\n",
    "        method_results_fpath = os.path.join('data', 'results', 'additional_results', f'{method}_all_results_kde.csv')\n",
    "        \n",
    "    if method == 'lstm':\n",
    "        rev_date = LSTM_ensemble_result_folder.split('_')[-1]\n",
    "        method_results_fpath = os.path.join('data', 'results', 'additional_results', f'{method}_all_results_{bitrate:02d}_bits_{rev_date}.csv')\n",
    "        if regularization_type == 'kde':\n",
    "            method_results_fpath = os.path.join('data', 'results', 'additional_results', f'{method}_all_results_kde_{rev_date}.csv')\n",
    "        \n",
    "    if os.path.exists(method_results_fpath):\n",
    "        results_dfs[method] = pd.read_csv(method_results_fpath, dtype={'Official_ID': str})\n",
    "        print(f'   Loaded {len(results_dfs[method])} {method} results from {method_results_fpath}')\n",
    "    else:\n",
    "        print(f'   {method} results not found in {method_results_fpath}, loading from individual station files...')\n",
    "        res_folder = os.path.join(results_folder, method)\n",
    "        if method == 'lstm':\n",
    "            res_folder = os.path.join(results_folder, f'{method}_{rev_date}')\n",
    "        args = [(stn, res_folder, method) for stn in completed_stns]\n",
    "        with Pool() as pool:\n",
    "            results_list = pool.map(dpf.load_results, args)\n",
    "\n",
    "        foo = pd.concat(results_list, ignore_index=True)\n",
    "        bad_dkl = foo[foo['KLD'].isna() | (foo['KLD'] < 0)].copy()\n",
    "        if not bad_dkl.empty:\n",
    "            print(f'Warning: {len(bad_dkl)} {method} rows with NaN or negative DKL values.')\n",
    "            bad_stns = bad_dkl['Official_ID'].values\n",
    "            raise Exception(f'Results have {len(bad_stns)} NaN or negative DKL values: {bad_stns}')\n",
    "        method_results = pd.concat(results_list, ignore_index=True)\n",
    "        results_dfs[method] = method_results\n",
    "        print(f'   Loaded {int(len(results_dfs[method])/len(set(completed_stns)))} station results for {method} results')\n",
    "        method_results.to_csv(method_results_fpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bc7051-29f9-42cf-94b5-d6aa1c936f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdc_df = pd.concat([results_dfs['parametric'], results_dfs['lstm']], axis=0)\n",
    "# fdc_df = results_dfs['parametric'].copy()\n",
    "np.unique(fdc_df['Label'].values)\n",
    "results_dfs['parametric'].keys()\n",
    "model_labels = sorted(list(set(fdc_df['Label'])))\n",
    "\n",
    "parametric_targets = list(set(results_dfs['parametric']['Label'].values))\n",
    "results_dfs['knn'] = split_knn_label_col(results_dfs['knn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23844b2-9307-4383-93e0-6d90f843733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_and_ids(label, metric):\n",
    "    data = fdc_df[fdc_df['Label'] == label].copy()\n",
    "    data = data.dropna(subset=[metric])\n",
    "    values = data[metric].values\n",
    "    if metric in ['NSE', 'KGE']:\n",
    "        # for NSE and KGE, we want to plot the upper bound as the maximum value\n",
    "        values = 1 - values\n",
    "    return values, data['Official_ID']\n",
    "\n",
    "\n",
    "def get_knn_group_results(tree_type='attribute', ensemble_type='freqEnsemble', weighting='ID2', k=7, which_set='knn'):\n",
    "    data = results_dfs[which_set].copy()\n",
    "    data = data[data['tree_type'] == 'attribute']\n",
    "    data = data[data['ensemble_method'] == ensemble_type]\n",
    "    data = data[data['ensemble_weight'] == weighting]\n",
    "    data = data[data['k'] == str(k)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ca5e81-b17a-479c-953c-cf862e8a03b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_result_vals = {}\n",
    "all_metrics = ['KLD', 'EMD', 'RMSE', 'PB', 'NSE', 'KGE', 'VE', 'NAE', 'MAPE']\n",
    "tree_type = 'attribute'\n",
    "# Define metrics that are naturally \"higher is better\" and need inversion to match \"lower is better\"\n",
    "invert_metrics = {'NSE', 'KGE', 'VE'}\n",
    "\n",
    "def invert_if_needed(values, dm):\n",
    "    \"\"\"Ensure metric values follow good = 0, bad = large positive\"\"\"\n",
    "    values = np.asarray(values)\n",
    "    if dm in invert_metrics:\n",
    "        if np.nanmin(values) < 0.:  # assumes values ~ [-inf, 1] if not yet inverted\n",
    "            return 1 - values\n",
    "    return values\n",
    "\n",
    "# Loop through each metric\n",
    "for dm in all_metrics:\n",
    "    # Parametric LN MoM\n",
    "    dml = dm\n",
    "    for label, name in [('PredictedMOM', 'LN MoM'), ('PredictedLog', 'LN Direct'), ('MLE', 'MLE')]:\n",
    "        data, ids = get_result_and_ids(label, dm)\n",
    "        data = invert_if_needed(data, dm)\n",
    "        main_result_vals[f'{name} {dml}'] = pd.DataFrame({'ids': ids, 'values': data})\n",
    "\n",
    "    # kNN group results\n",
    "    for k in [2, 4, 8]:\n",
    "        knn_df = get_knn_group_results(k=k)\n",
    "        data = invert_if_needed(knn_df[dm].values, dm)\n",
    "        ids = knn_df['Official_ID'].values\n",
    "        main_result_vals[f'{k} kNN {dml}'] = pd.DataFrame({'ids': ids, 'values': data})\n",
    "\n",
    "    # LSTM models\n",
    "    for label, suffix in [('time', 'LSTM time'), ('frequency', 'LSTM dist.')]:\n",
    "        subset = fdc_df[fdc_df['Label'] == label]\n",
    "        data = invert_if_needed(subset[dm].values, dm)\n",
    "        ids = subset['Official_ID'].values\n",
    "        main_result_vals[f'{suffix} {dml}'] = pd.DataFrame({'ids': ids, 'values': data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba75d83-45a6-4e09-a43c-1caec48a8225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with all the model results indexed by station\n",
    "all_results = []\n",
    "for m in main_result_vals.keys():\n",
    "    df = main_result_vals[m].copy()\n",
    "    df.rename(columns={'values': m}, inplace=True)\n",
    "    df.set_index('ids', inplace=True)\n",
    "    all_results.append(df)\n",
    "all_results_df = pd.concat(all_results, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c2cea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the complete years previously processed\n",
    "complete_year_dict = np.load('data/complete_year_stats.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21e971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load baseline distributions to get global support grid\n",
    "fname = 'pmf_obs.csv'\n",
    "if regularization_type == 'kde':\n",
    "    print('Using KDE regularization for PMF estimation.')\n",
    "    fname = 'pmf_kde.csv'\n",
    "pmf_path = Path(os.getcwd()) / 'data' / 'baseline_distributions' / f'{bitrate:02d}_bits' / fname\n",
    "pmf_obs_df = pd.read_csv(pmf_path)\n",
    "baseline_log_grid = pmf_obs_df['log_x_uar'].values\n",
    "# baseline_log_edges = np.concatenate([pmf_obs_df['left_log_edges'].values[:1], pmf_obs_df['right_log_edges'].values])\n",
    "# baseline_log_w = np.diff(baseline_log_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b3b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_LSTM_outputs(stn_data, folder):\n",
    "    all_dfs = []\n",
    "    stn = stn_data.target_stn\n",
    "    da = stn_data.target_da\n",
    "    obs_cols = []\n",
    "    for date, clr in zip(['20250514', '20250627'], ['black', 'red']):\n",
    "        fpath = folder / f'ensemble_results_{date}' / f'{stn}_ensemble.csv'\n",
    "        if not os.path.exists(fpath):\n",
    "            return pd.DataFrame()\n",
    "        df = pd.read_csv(fpath)\n",
    "        df.rename(columns={'Unnamed: 0': 'time'}, inplace=True)\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        df.set_index('time', inplace=True)\n",
    "        df.columns = [f'{c}_{date}' for c in df.columns]\n",
    "        obs_cols += [c for c in df.columns if c.startswith('streamflow_obs')]\n",
    "        df = np.exp(df)\n",
    "        all_dfs.append(df)\n",
    "    result = pd.concat(all_dfs, axis=1, join='inner')\n",
    "    result = result.dropna(how='any', axis=0)\n",
    "    result['discharge'] = result[obs_cols[0]]\n",
    "    # complete_years = complete_year_dict.get(stn, None).get('hyd_years', [])\n",
    "    cal_df, hyd_df = stn_data.filter_complete_hydrological_years(result, da, min_days=20)\n",
    "    # print(f'    Found {len(complete_years)} complete years for {stn}: {complete_years}')\n",
    "    return hyd_df\n",
    "\n",
    "\n",
    "def plot_ensemble_results(stn, folder):\n",
    "    \"\"\"Plot the ensemble results for a given station.\"\"\"\n",
    "    p = figure(title=f'Ensemble results for {stn}', x_axis_type='datetime', \n",
    "               y_axis_type='log', width=800, height=400)\n",
    "\n",
    "    for date, clr in zip(['20250514', '20250627'], ['black', 'red']):\n",
    "        fpath = folder / f'ensemble_results_{date}' / f'{stn}_ensemble.csv'\n",
    "        df = pd.read_csv(fpath)\n",
    "        df.rename(columns={'Unnamed: 0': 'time'}, inplace=True)\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        df.set_index('time', inplace=True)\n",
    "        df = np.exp(df)\n",
    "        if 'streamflow_obs' in df.columns:\n",
    "            p.line(df.index, df['streamflow_obs'], color=clr, legend_label=f'{date} Obs', line_width=2)\n",
    "        \n",
    "        sim_cols = [c for c in df.columns if c.startswith('streamflow_sim')]\n",
    "        mean_sim = df[sim_cols].mean(axis=1)\n",
    "        # compute the 5% quantiles on the simulation columns\n",
    "        lb = df[sim_cols].quantile(0.05, axis=1)\n",
    "        ub = df[sim_cols].quantile(0.95, axis=1)\n",
    "\n",
    "        p.varea(df.index, lb, ub, color=clr, alpha=0.2, legend_label=f'{date} 90% CI')\n",
    "        p.line(df.index, mean_sim, color=clr, legend_label=f'{date} Mean', line_dash='dashed', line_width=2)\n",
    "\n",
    "    p.legend.location = 'top_left'\n",
    "    p.xaxis.axis_label = 'Time'\n",
    "    p.yaxis.axis_label = 'Streamflow (L/s/km2)'\n",
    "    p.legend.click_policy= 'hide'\n",
    "    return p\n",
    "\n",
    "\n",
    "def compute_afdcs_from_sorted_flows(df, years, da, date):\n",
    "    \"\"\"Compute AFDCs from sorted daily flows, rather than PDFs.\"\"\"\n",
    "    \n",
    "    obs_cols = [c for c in df.columns if c.startswith('streamflow_obs') and c.endswith(date)]\n",
    "    assert len(obs_cols) == 1, f'Expected one observed column, found {len(obs_cols)}'\n",
    "    sim_cols = [c for c in df.columns if c.startswith('streamflow_sim') and c.endswith(date)]\n",
    "    assert len(sim_cols) == 10, f'Expected 10 simulated columns, found {len(sim_cols)}'\n",
    "\n",
    "    afdc_obs, afdc_sim = [], []\n",
    "\n",
    "    for year in years:\n",
    "        year_df = df[df.index.year == year]\n",
    "\n",
    "        # Observed\n",
    "        obs_values = year_df[obs_cols[0]].dropna().values\n",
    "        if len(obs_values) > 0:\n",
    "            sorted_obs = np.sort(obs_values)[::-1]  # descending\n",
    "            afdc_obs.append(pd.Series(sorted_obs, name=f\"{year}_obs\"))\n",
    "\n",
    "        # Simulated ensemble mean\n",
    "        sim_ensemble = year_df[sim_cols].dropna(how='all')  # drop rows with all NaNs\n",
    "        if not sim_ensemble.empty:\n",
    "            sim_mean = sim_ensemble.mean(axis=1).dropna().values\n",
    "            sorted_sim = np.sort(sim_mean)[::-1]\n",
    "            afdc_sim.append(pd.Series(sorted_sim, name=f\"{year}_sim\"))\n",
    "\n",
    "    # Align lengths: trim to shortest year\n",
    "    min_len = min(len(s) for s in afdc_obs + afdc_sim)\n",
    "    afdc_obs_trimmed = [s.iloc[:min_len].reset_index(drop=True) for s in afdc_obs]\n",
    "    afdc_sim_trimmed = [s.iloc[:min_len].reset_index(drop=True) for s in afdc_sim]\n",
    "\n",
    "    # Combine into DataFrames\n",
    "    obs_df = pd.concat(afdc_obs_trimmed, axis=1)\n",
    "    sim_df = pd.concat(afdc_sim_trimmed, axis=1)\n",
    "\n",
    "    # Compute percentile summary\n",
    "    afdc_summary = pd.DataFrame(index=np.arange(1, min_len + 1))\n",
    "    afdc_summary[f'AFDC50_obs_{date}'] = obs_df.median(axis=1)\n",
    "    afdc_summary[f'AFDC10_obs_{date}'] = obs_df.quantile(0.10, axis=1)\n",
    "    afdc_summary[f'AFDC90_obs_{date}'] = obs_df.quantile(0.90, axis=1)\n",
    "\n",
    "    afdc_summary[f'AFDC50_sim_{date}'] = sim_df.median(axis=1)\n",
    "    afdc_summary[f'AFDC10_sim_{date}'] = sim_df.quantile(0.10, axis=1)\n",
    "    afdc_summary[f'AFDC90_sim_{date}'] = sim_df.quantile(0.90, axis=1)\n",
    "\n",
    "    afdc_summary.index.name = 'Rank'\n",
    "    return afdc_summary\n",
    "\n",
    "\n",
    "def compute_ensemble_pmfs(df, sim_cols, stn_data):\n",
    "    \"\"\"Compute the frequency mean PMF for the simulated ensemble.\"\"\"\n",
    "    sim_ensemble_pmfs = []\n",
    "    \n",
    "    for sim_col in sim_cols:\n",
    "        sim_vals = df[sim_col].dropna().values # should be uar\n",
    "        assert len(sim_vals) > 0, f'No valid values found for {sim_col}'\n",
    "        sim_pmf = stn_data.build_pmf_from_timeseries(sim_vals, stn_data.min_measurable_log_uar, stn_data.target_da)\n",
    "        sim_ensemble_pmfs.append(pd.Series(sim_pmf, index=baseline_log_grid, name=sim_col))\n",
    "    # concatenate all PMFs and compute the mean\n",
    "    return pd.concat(sim_ensemble_pmfs, axis=1)\n",
    "\n",
    "\n",
    "def compute_series_range(pmf, grid, threshold=1e-4):\n",
    "    # Find indices where pmf is above the threshold\n",
    "    valid_idx = np.where(pmf >= threshold)[0]\n",
    "    if len(valid_idx) > 0:\n",
    "        left_bound = grid[valid_idx[0]]\n",
    "        right_bound = grid[valid_idx[-1]]\n",
    "    else:\n",
    "        # Fallback if all values are below threshold\n",
    "        left_bound = grid[0]\n",
    "        right_bound = grid[-1]\n",
    "    return left_bound, right_bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba270a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 1, 1, 0.5, 0.2, 0])\n",
    "np.argmax(a < 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2173e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_pmf_for_zero_flows(log_uar_data, station_data):\n",
    "    \"\"\"Adjust PMF to account for zero flows.\"\"\"\n",
    "    log_edges_uar = station_data.log_edges_extended\n",
    "    pmf_arr = np.zeros(len(log_edges_uar) - 1)\n",
    "\n",
    "    # add the zero-flow bin counts as the first bin\n",
    "    z_index = station_data.zero_bin_index\n",
    "    pmf_arr[z_index] = (log_uar_data < np.log(station_data.min_measurable_uar)).sum()\n",
    "\n",
    "\n",
    "    # Empirical (counts -> pmf/pdf)\n",
    "    # log_edges count the positive flows only\n",
    "    counts, edges = np.histogram(log_uar_data, bins=log_edges_uar, density=False)\n",
    "    counts = counts.astype(int)\n",
    "\n",
    "    # add the non-zero empirical counts to the arrays\n",
    "    # if z_index > 0:\n",
    "    #     print(z_index, (log_uar_data < np.log(station_data.min_measurable_uar)).sum())\n",
    "    #     print(pmf_arr[z_index-2:z_index+3], counts[z_index-2:z_index+3])\n",
    "    \n",
    "\n",
    "    pmf_arr[z_index:] = counts[z_index:]\n",
    "    # if z_index > 0:\n",
    "    #     print(pmf_arr[z_index-2:z_index+3], counts[z_index-2:z_index+3])\n",
    "\n",
    "    return pmf_arr / np.sum(pmf_arr)\n",
    "\n",
    "\n",
    "def plot_observed_and_simulated_pdf(stn, pmf_dfs, og_df, date, stn_data, pdf_plots=[]):\n",
    "    \"\"\"Plot the observed and simulated PDFs for a given station.\"\"\"\n",
    "\n",
    "    log_w = stn_data.log_w\n",
    "    da = stn_data.target_da\n",
    "    max_p = 0\n",
    "\n",
    "    baseline_lin_grid = np.exp(baseline_log_grid)\n",
    "    lbs, rbs = [], []\n",
    "\n",
    "    if date == '20250514':\n",
    "        title = f'{stn} ({da} km²): LSTM PDFs Mean NSE Objective'\n",
    "    elif date == '20250627':\n",
    "        title = f'{stn} ({da} km²): LSTM PDFs 95% Quantile Objective'\n",
    "    if len(pdf_plots) > 0:\n",
    "        p = figure(title=title, x_axis_type='log', toolbar_location='above',\n",
    "            width=1000, height=350, x_range=pdf_plots[0].x_range,\n",
    "            y_range=pdf_plots[0].y_range)\n",
    "    else:\n",
    "        p = figure(title=title, x_axis_type='log',toolbar_location='above', \n",
    "            width=1000, height=350)\n",
    "\n",
    "    # plot the observed values as quad glyphs\n",
    "    observed_vals = og_df[f'{stn}_uar'].dropna().values\n",
    "    observed_log_vals = np.log(observed_vals)\n",
    "    edges = np.exp(stn_data.log_edges_extended)  # convert edges back to linear space\n",
    "    \n",
    "    hist = adjust_pmf_for_zero_flows(observed_log_vals, stn_data) / log_w    \n",
    "    # convert to probbility mass function (PMF)\n",
    "    \n",
    "    p.quad(top=hist, bottom=0.99 * min(hist), left=edges[:-1], right=edges[1:],\n",
    "            fill_color='dodgerblue', alpha=0.5, legend_label='Observed')\n",
    "    max_p = max(max_p, np.max(hist))\n",
    "\n",
    "    df = pmf_dfs[date].copy()\n",
    "\n",
    "    for i in range(10):\n",
    "        sim_col = f'streamflow_sim_{i}_{date}'\n",
    "        if sim_col in df.columns:\n",
    "            vals = df[sim_col].values / log_w\n",
    "            lb, rb = compute_series_range(vals, baseline_lin_grid, threshold=1e-4)\n",
    "            lbs.append(lb)\n",
    "            rbs.append(rb)\n",
    "            p.line(baseline_lin_grid, vals, color='grey', alpha=0.5, \n",
    "                    legend_label=f'LSTM Ensemble')\n",
    "            max_p = max(max_p, np.max(vals))\n",
    "\n",
    "    # convert pmfs to pdfs\n",
    "    # obs_vals = df[f'POR_obs_{date}'].values / log_w\n",
    "    # max_p = max(max_p, np.max(obs_vals))\n",
    "    # lb, rb = compute_series_range(obs_vals, baseline_lin_grid, threshold=1e-4)\n",
    "    # lbs.append(lb)\n",
    "    # rbs.append(rb)\n",
    "    # p.line(baseline_lin_grid, obs_vals, \n",
    "    #        color='black', line_width=2.5, legend_label=f'POR Observed', line_dash='dotted')\n",
    "    sim_time_vals = df[f'POR_sim_timeEnsemble_{date}'].values\n",
    "    sim_time_pmf = np.zeros_like(sim_time_vals)\n",
    "    sim_time_pmf[stn_data.zero_bin_index] = sim_time_vals[:stn_data.zero_bin_index].sum()\n",
    "    sim_time_pmf[stn_data.zero_bin_index:] = sim_time_vals[stn_data.zero_bin_index:]\n",
    "    p.line(baseline_lin_grid, sim_time_pmf / log_w, \n",
    "           line_width=2.5, color='green', legend_label=f'timeEnsemble', line_dash='dashed')\n",
    "    sim_dist_vals = df[f'POR_sim_distEnsemble_{date}'].values \n",
    "    sim_dist_pmf = np.zeros_like(sim_dist_vals)\n",
    "    sim_dist_pmf[stn_data.zero_bin_index] = sim_dist_vals[:stn_data.zero_bin_index].sum()\n",
    "    sim_dist_pmf[stn_data.zero_bin_index:] = sim_dist_vals[stn_data.zero_bin_index:]\n",
    "    lb, rb = compute_series_range(sim_dist_pmf / log_w, baseline_lin_grid, threshold=1e-4)\n",
    "    lbs.append(lb)\n",
    "    rbs.append(rb)\n",
    "    p.line(baseline_lin_grid, sim_dist_pmf / log_w, \n",
    "           line_width=2.5, color='green', legend_label=f'distEnsemble')\n",
    "    max_p = max(max_p, np.max(vals), np.max(sim_time_vals), np.max(sim_dist_vals))\n",
    "    le, re = np.exp(stn_data.log_edges_extended[0]), stn_data.zero_equiv_uar\n",
    "\n",
    "    p.quad(top=max_p * 1.01, bottom=0, left=le, right=re, \n",
    "           fill_color='black', line_color=None, fill_alpha=0.1, legend_label='Zero-equiv.')\n",
    "    \n",
    "    clrs = ['orange', 'purple']\n",
    "    lss = ['solid', 'dashed', 'dotted']\n",
    "    cols = list(pmf_dfs.keys())\n",
    "    for i, lb in enumerate(['LN', 'KNN']):\n",
    "        model_cols = [c for c in cols if c.startswith(lb)]\n",
    "        for j, mc in enumerate(model_cols):\n",
    "            zf_index = stn_data.zero_bin_index\n",
    "            pmf = np.array(pmf_dfs[mc].copy())\n",
    "            low_p = float(np.sum(pmf[:zf_index]))\n",
    "            pmf[:zf_index] = 0.\n",
    "            pmf[zf_index] = low_p\n",
    "            mc_pdf = pmf / log_w\n",
    "            lb, rb = compute_series_range(mc_pdf, baseline_lin_grid, threshold=1e-4)\n",
    "            lbs.append(lb)\n",
    "            rbs.append(rb)\n",
    "            p.line(baseline_lin_grid, mc_pdf, line_color=clrs[i], line_dash=lss[j], \n",
    "                   legend_label=f'{mc}', line_width=2.5)\n",
    "    \n",
    "    l = max(stn_data.zero_bin_index - 2, 0)\n",
    "    p.x_range.start = baseline_lin_grid[l] \n",
    "    p.x_range.end = np.max(rbs)\n",
    "\n",
    "    p.xaxis.axis_label = 'Log Unit Area Runoff (L/s/km2)'\n",
    "    p.xaxis.axis_label = 'Unit Area Runoff (L/s/km2)'\n",
    "    p.yaxis.axis_label = 'Probability Density'\n",
    "    p.legend.location = 'top_left'\n",
    "    p.legend.click_policy = 'hide'\n",
    "    p.add_layout(p.legend[0], 'left')\n",
    "    return p, baseline_log_grid, baseline_lin_grid, log_w\n",
    "\n",
    "\n",
    "def plot_observed_and_simulated_fdc(stn, pmf_dfs, baseline_lin_grid, lstm_df, og_df, date, stn_data, fdc_plots=[]):\n",
    "    \"\"\"Plot the observed and simulated FDCs for a given station.\"\"\"\n",
    "\n",
    "    # baseline_lin_grid = np.exp(baseline_log_grid)\n",
    "    zi = stn_data.zero_bin_index\n",
    "    if date == '20250514':\n",
    "        title = f'{stn}: FDCs'\n",
    "    elif date == '20250627':\n",
    "        title = f'{stn}: FDCs'\n",
    "\n",
    "    if len(fdc_plots) > 0:\n",
    "        fdc_plot = figure(title=title, y_axis_type='log',\n",
    "            width=600, height=350, x_range=fdc_plots[0].x_range,\n",
    "            y_range=fdc_plots[0].y_range, toolbar_location='above')\n",
    "    else:\n",
    "        fdc_plot = figure(title=title, toolbar_location='above', \n",
    "                          width=600, height=350, y_axis_type='log')\n",
    "        \n",
    "    # plot the observed duration curve\n",
    "    # pcts = np.linspace(0.01, 0.99, 99) * 100\n",
    "    observed_vals = og_df[f'{stn}_uar'].dropna().values\n",
    "    obs_pmf = stn_data.build_pmf_from_timeseries(observed_vals, stn_data.min_measurable_log_uar, stn_data.target_da)\n",
    "    z = 1e-9\n",
    "    obs_cdf = np.cumsum(obs_pmf)\n",
    "    obs_fdc = 1 - obs_cdf\n",
    "    # diffs = np.r_[stn_data.zero_bin_index == 0, ~np.isclose(np.diff(obs_fdc), 0.0)]\n",
    "    # get the index of the last value >= 1.0\n",
    "    \n",
    "    ci, ce = int(np.argmax(obs_fdc < 1.0)- 1), np.argmax(obs_fdc == np.min(obs_fdc)) + 1\n",
    "    # obs_fdc = np.percentile(observed_vals, pcts)[::-1]\n",
    "    # obs_fdc = np.clip(obs_fdc, a_min=stn_data.min_measurable_uar, a_max=None)\n",
    "    fdc_plot.line(obs_fdc[ci:ce], baseline_lin_grid[ci:ce], color='dodgerblue', line_width=2.5, legend_label=f'Observed')\n",
    "\n",
    "    sim_cols = [c for c in lstm_df.columns if c.startswith('streamflow_sim') and c.endswith(date)]\n",
    "    assert len(sim_cols) == 10, f'Expected 10 simulated columns, found {len(sim_cols)}'\n",
    "\n",
    "    # sim_fdcs = pd.DataFrame(index=pcts)\n",
    "    sim_fdcs = pd.DataFrame(index=baseline_lin_grid)\n",
    "    for i, sim_col in enumerate(sim_cols):\n",
    "        sim_vals = lstm_df[sim_col].dropna().values\n",
    "        sim_pmf = stn_data.build_pmf_from_timeseries(sim_vals, stn_data.min_measurable_log_uar, stn_data.target_da)\n",
    "        sim_cdf = np.cumsum(sim_pmf)\n",
    "        sim_fdc = 1 - sim_cdf\n",
    "        ci, ce = int(np.argmax(sim_fdc < 1.0)- 1), np.argmax(sim_fdc == np.min(sim_fdc)) + 1\n",
    "        # get the percentile values of the simulated flows\n",
    "        sim_fdcs[f'LSTM Simulation {i+1}'] = sim_fdc\n",
    "        fdc_plot.line(sim_fdc[ci:ce], baseline_lin_grid[ci:ce], color='grey', alpha=0.5, \n",
    "                      legend_label=f'LSTM Simulation')\n",
    "\n",
    "    # compute the temporal ensemble mean FDC\n",
    "    temporal_mean_ts = lstm_df[sim_cols].mean(axis=1).dropna().values\n",
    "    temporal_mean_pmf = stn_data.build_pmf_from_timeseries(temporal_mean_ts, stn_data.min_measurable_log_uar, stn_data.target_da)\n",
    "    temporal_mean_cdf = np.cumsum(temporal_mean_pmf)\n",
    "    time_ensemble_fdc = 1 - temporal_mean_cdf\n",
    "    # get the index of the first value equal to 1.\n",
    "    # keep = np.r_[True, ~np.isclose(np.diff(time_ensemble_fdc), 0.0)]\n",
    "    ci, ce = int(np.argmax(time_ensemble_fdc < 1.0) - 1), np.argmax(time_ensemble_fdc == np.min(time_ensemble_fdc)) + 1\n",
    "    # time_ensemble_fdc = np.percentile(temporal_mean_fdc, baseline_lin_grid)[::-1]\n",
    "    fdc_plot.line(time_ensemble_fdc[ci:ce], \n",
    "                  baseline_lin_grid[ci:ce], color='green', \n",
    "                  line_width=2.5, line_dash='dashed',\n",
    "                  legend_label=f'LSTM Time')\n",
    "    \n",
    "    # compute the frequency ensemble mean FDC\n",
    "    freq_ensemble_fdc = sim_fdcs.mean(axis=1).values\n",
    "    ci, ce = int(np.argmax(freq_ensemble_fdc < 1.0) - 1), np.argmax(freq_ensemble_fdc == np.min(freq_ensemble_fdc)) + 1\n",
    "    fdc_plot.line(freq_ensemble_fdc[ci:ce], \n",
    "                  baseline_lin_grid[ci:ce], \n",
    "                  color='green', line_width=2.5, \n",
    "                  legend_label=f'LSTM Dist.')\n",
    "    \n",
    "    clrs = ['orange', 'purple']\n",
    "    lss = ['solid', 'dashed', 'dotted']\n",
    "    cols = list(pmf_dfs.keys())\n",
    "    fdc_metrics = {}\n",
    "    fdc_metrics['distEnsemble'] = float((freq_ensemble_fdc - obs_fdc).sum())\n",
    "    fdc_metrics['timeEnsemble'] = float((time_ensemble_fdc - obs_fdc).sum())\n",
    "    for i, lb in enumerate(['LN', 'KNN']):\n",
    "        model_cols = [c for c in cols if c.startswith(lb)]\n",
    "        for j, mc in enumerate(model_cols):\n",
    "            mc_pmf = np.array(pmf_dfs[mc].copy())\n",
    "            low_p = float(np.sum(mc_pmf[:stn_data.zero_bin_index]))\n",
    "            mc_pmf[:stn_data.zero_bin_index] = 0.\n",
    "            mc_pmf[stn_data.zero_bin_index] = low_p\n",
    "            mc_pmf /= np.sum(mc_pmf)\n",
    "            assert np.isclose(np.sum(mc_pmf), 1.0), f'Model PMF for {mc} does not sum to 1 (sums to {np.sum(mc_pmf)})'\n",
    "            # compute the cdf\n",
    "            mc_cdf = np.cumsum(mc_pmf) \n",
    "            # interpolate between the percentiles to get the 1, 99 percentile values\n",
    "            fdc = 1 - mc_cdf\n",
    "            # keep = np.r_[True, ~np.isclose(np.diff(obs_fdc), 0.0)]\n",
    "            ci, ce = int(np.argmax(fdc < 1.0) - 1), np.argmax(fdc == np.min(fdc)) + 1\n",
    "            # print(fdc[ci], fdc[min(len(fdc)-1, ce)])\n",
    "            # assert ce < ci, f'Invalid indices for FDC plotting: ci={ci}, ce={ce}'\n",
    "            # model_vals = np.interp(pcts, mc_cdf, baseline_lin_grid)\n",
    "            # fdc_metrics[f'{mc}'] = float((model_vals - obs_fdc).sum())\n",
    "            fdc_plot.line(fdc[ci:ce], baseline_lin_grid[ci:ce], \n",
    "                          line_color=clrs[i], line_dash=lss[j],\n",
    "                          legend_label=f'{mc}', line_width=2.5)\n",
    "            # fdc_plot.line(pcts, model_vals[::-1], line_color=clrs[i], line_dash=lss[j],\n",
    "            #         legend_label=f'{mc}', line_width=2.5)\n",
    "    \n",
    "    fdc_plot.xaxis.axis_label = 'Exceedance Probability (%)'\n",
    "    fdc_plot.legend.background_fill_alpha = 0.5\n",
    "    fdc_plot.add_layout(fdc_plot.legend[0], 'left')\n",
    "    fdc_plot.yaxis.axis_label = 'Unit Area Runoff (L/s/km2)'\n",
    "    fdc_plot.legend.location = 'top_right'\n",
    "    fdc_plot.legend.click_policy = 'hide'\n",
    "    \n",
    "    return fdc_plot, None#fdc_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39962a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_station_in_hydat(stn, conn):\n",
    "    # Query to check if the station exists\n",
    "    check_query = \"\"\"\n",
    "    SELECT STATION_NUMBER, STATION_NAME\n",
    "    FROM STATIONS\n",
    "    WHERE STATION_NUMBER = ?\n",
    "    \"\"\"\n",
    "    # Run the query\n",
    "    station_check = pd.read_sql_query(check_query, conn, params=(stn,))\n",
    "\n",
    "    # Test if any result was returned\n",
    "    if station_check.empty:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "\n",
    "def query_data_symbols(stn):\n",
    "    hydat_path = Path('/home/danbot/code/common_data/HYDAT') / 'Hydat_20250715.sqlite3'\n",
    "    # Connect to the database\n",
    "    conn = sqlite3.connect(hydat_path)\n",
    "    # Query all data symbols\n",
    "    query = \"SELECT SYMBOL_ID, SYMBOL_EN FROM DATA_SYMBOLS ORDER BY SYMBOL_ID\"\n",
    "    try:\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        return df.set_index('SYMBOL_ID')['SYMBOL_EN']\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def reshape_hydat_wide(df):\n",
    "    # First, ensure all FLOW_SYMBOL columns exist and are named correctly\n",
    "    id_vars = [\"STATION_NUMBER\", \"YEAR\", \"MONTH\", \"NO_DAYS\"]\n",
    "    \n",
    "    # Melt flows\n",
    "    flow_df = df.melt(id_vars=id_vars, \n",
    "                      value_vars=[f\"FLOW{i}\" for i in range(1, 32)],\n",
    "                      var_name=\"day\", value_name=\"flow\")\n",
    "\n",
    "    # Melt symbols\n",
    "    sym_df = df.melt(id_vars=id_vars, \n",
    "                     value_vars=[f\"FLOW_SYMBOL{i}\" for i in range(1, 32)],\n",
    "                     var_name=\"day\", value_name=\"flow_symbol\")\n",
    "\n",
    "    # Extract day number\n",
    "    flow_df[\"day\"] = flow_df[\"day\"].str.extract(r\"(\\d+)$\").astype(int)\n",
    "    sym_df[\"day\"] = sym_df[\"day\"].str.extract(r\"(\\d+)$\").astype(int)\n",
    "\n",
    "    # Merge on ID columns + day\n",
    "    merged = pd.merge(flow_df, sym_df, on=id_vars + [\"day\"])\n",
    "\n",
    "    # Construct date\n",
    "    merged[\"date\"] = pd.to_datetime(dict(year=merged[\"YEAR\"], \n",
    "                                         month=merged[\"MONTH\"], \n",
    "                                         day=merged[\"day\"]), errors='coerce')\n",
    "\n",
    "    # Filter out invalid days (e.g., day > NO_DAYS)\n",
    "    merged = merged[merged[\"day\"] <= merged[\"NO_DAYS\"]]\n",
    "    formatted_df = merged[[\"STATION_NUMBER\", \"date\", \"flow\", \"flow_symbol\"]].dropna(subset=[\"flow\"])\n",
    "    formatted_df.set_index('date', inplace=True)\n",
    "    return formatted_df\n",
    "\n",
    "\n",
    "def query_hydat_database(stn):\n",
    "    \"\"\"Query the HYDAT database for a given station and date range.\"\"\"\n",
    "    hydat_path = Path('/home/danbot/code/common_data/HYDAT') / 'Hydat_20250715.sqlite3'\n",
    "    # Connect to the database\n",
    "    conn = sqlite3.connect(hydat_path)\n",
    "\n",
    "    station_in_hydat = check_if_station_in_hydat(stn, conn)\n",
    "    if station_in_hydat is False:\n",
    "        print(f'Station {stn} not found in HYDAT database.')\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    base_columns = [\"STATION_NUMBER\", \"YEAR\", \"MONTH\"]\n",
    "    flow_columns = [f\"FLOW{i}, FLOW_SYMBOL{i}\" for i in range(1, 32)]\n",
    "    end_columns = [\"NO_DAYS\"]\n",
    "\n",
    "    all_columns = base_columns + flow_columns + end_columns\n",
    "    column_str = \",\\n    \".join(all_columns)\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        {column_str}\n",
    "    FROM DLY_FLOWS\n",
    "    WHERE STATION_NUMBER = ?\n",
    "    ORDER BY YEAR, MONTH;\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn, params=(stn,))\n",
    "\n",
    "    if df.empty:\n",
    "        print(f'No data found for {stn} in HYDAT.')\n",
    "        return pd.DataFrame()\n",
    "    df = reshape_hydat_wide(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def find_symbol_segments(symbol_df, target_symbol):\n",
    "    \"\"\"Return (start, end) date pairs for each continuous period of target_symbol.\"\"\"\n",
    "    # Filter for matching symbol only\n",
    "    mask = (symbol_df['flow_symbol'] == target_symbol)\n",
    "    dates = symbol_df['flow_symbol'].index[mask]\n",
    "\n",
    "    if dates.empty:\n",
    "        return []\n",
    "\n",
    "    # Compute gaps in days between successive dates\n",
    "    gaps = dates.to_series().diff().gt(pd.Timedelta(days=1)).fillna(True)\n",
    "\n",
    "    # Group by contiguous regions (cumsum creates a new group after each gap)\n",
    "    group_ids = gaps.cumsum()\n",
    "\n",
    "    # Group by group ID and extract start and end of each contiguous block\n",
    "    segments = [(group.min(), group.max()) for _, group in dates.to_series().groupby(group_ids)]\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a29d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quality_flag_periods(stn, df, hydat_df, quality_symbols, runoff_plot, obs_col):\n",
    "    symbol_dict = quality_symbols.to_dict()\n",
    "    symbol_colors = {\n",
    "        'B': 'dodgerblue',  # Baseflow\n",
    "        'D': 'firebrick',  # Dry weather flow\n",
    "        'E': 'orange',  # Estimated\n",
    "    }\n",
    "    df['flow_symbol'] = hydat_df['flow_symbol'].reindex(df.index, method=None)\n",
    "    uar_cols = obs_col + [c for c in df.columns if c.startswith('streamflow_sim')]\n",
    "\n",
    "    for symbol in ['B', 'D', 'E']:\n",
    "        description = symbol_dict.get(symbol, {})\n",
    "        color = symbol_colors.get(symbol, 'gray')\n",
    "        n_symbols = df['flow_symbol'].eq(symbol).sum()\n",
    "        if n_symbols == 0:\n",
    "            continue\n",
    "\n",
    "        segments = find_symbol_segments(df[['flow_symbol']].copy(), symbol)\n",
    "\n",
    "        for start, end in segments:\n",
    "            runoff_plot.varea(\n",
    "                x=pd.date_range(start, end),\n",
    "                y1=0.98 * df[uar_cols].min().min(),  # get the min of the dataframe for the lower bound\n",
    "                y2=1.02 * df[uar_cols].max().max(),  # a bit above max for visibility\n",
    "                fill_color=color, fill_alpha=0.3,\n",
    "                legend_label=f\"{description} ({symbol})\"\n",
    "            )\n",
    "    \n",
    "    df['flow'] = hydat_df['flow'].reindex(df.index, method=None)\n",
    "    df['hydat_uar'] = 1000 * df['flow'] / da_dict[stn]  # convert to unit area runoff (L/s/km2)\n",
    "    runoff_plot.line(df.index, df['hydat_uar'],\n",
    "                     color='dodgerblue', legend_label='HYDAT UAR', \n",
    "                     line_width=2, line_dash='dotted')\n",
    "    return runoff_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50012f63-aad3-40a2-82a5-ab913bb07b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_zero_flow_periods(stn, df, runoff_plot, obs_col):\n",
    "\n",
    "    color = 'salmon'\n",
    "    n_symbols = (df['zero_flow_flag'] == True).sum()\n",
    "    if n_symbols == 0:\n",
    "        return runoff_plot\n",
    "\n",
    "    df.rename({'zero_flow_flag': 'flow_symbol'}, inplace=True, axis=1)\n",
    "\n",
    "    segments = find_symbol_segments(df[['flow_symbol']].copy(), True)\n",
    "    for start, end in segments:\n",
    "        runoff_plot.varea(\n",
    "            x=pd.date_range(start, end),\n",
    "            y1=0.98 * df[f'{stn}_uar'].min(),  # get the min of the dataframe for the lower bound\n",
    "            y2=1.02 * df[f'{stn}_uar'].max(),  # a bit above max for visibility\n",
    "            fill_color=color, fill_alpha=0.3,\n",
    "            legend_label=f\"Q=0 replaced\"\n",
    "        )\n",
    "    runoff_plot.line(df.index, df[f'{stn}_uar'],\n",
    "                     color='purple', legend_label='UAR', \n",
    "                     line_width=2, line_dash='dotted')\n",
    "    return runoff_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073de4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_FDCs(stn, og_df, lstm_df, result_folder, station_data):\n",
    "    pmf_dfs, por_metrics, other_metrics = {}, {}, {}\n",
    "    # load the parametric result\n",
    "    parametric_fpath = result_folder / 'parametric' / f'{stn}_fdc_results.json'\n",
    "    # if not os.path.exists(parametric_fpath):\n",
    "    #     raise xception(f'Parametric results for {stn} not found at {parametric_fpath}')\n",
    "    with open(parametric_fpath, 'r') as f:\n",
    "        parametric_results = json.load(f)\n",
    "    other_metrics[f'LN_MLE'] = parametric_results['MLE']['eval']\n",
    "    other_metrics[f'LN_PredictedLog'] = parametric_results['PredictedLog']['eval']\n",
    "    other_metrics[f'LN_PredictedMOM'] = parametric_results['PredictedMOM']['eval']\n",
    "    pmf_dfs['LN_MLE'] = parametric_results['MLE']['pmf']\n",
    "    pmf_dfs['LN_PredictedLog'] = parametric_results['PredictedLog']['pmf']\n",
    "    pmf_dfs['LN_PredictedMOM'] = parametric_results['PredictedMOM']['pmf']\n",
    "\n",
    "    knn_fpath = result_folder / 'knn' / f'{stn}_fdc_results.json'\n",
    "    with open(knn_fpath, 'r') as f:\n",
    "        knn_results = json.load(f)\n",
    "    knn_cols = list(knn_results.keys())\n",
    "    nn2 = [c for c in knn_cols if '2_NN_attribute_dist_ID2_freqEnsemble' in c]\n",
    "    nn4 = [c for c in knn_cols if '4_NN_attribute_dist_ID2_freqEnsemble' in c]\n",
    "    nn8 = [c for c in knn_cols if '8_NN_attribute_dist_ID2_freqEnsemble' in c]\n",
    "\n",
    "    nn2_pmf = knn_results[nn2[0]]['pmf']\n",
    "    nn4_pmf = knn_results[nn4[0]]['pmf']\n",
    "    nn8_pmf = knn_results[nn8[0]]['pmf']\n",
    "    pmf_dfs['KNN_2_NN'] = nn2_pmf\n",
    "    pmf_dfs['KNN_4_NN'] = nn4_pmf\n",
    "    pmf_dfs['KNN_8_NN'] = nn8_pmf\n",
    "\n",
    "    other_metrics[f'KNN_2_NN'] = knn_results[nn2[0]]['eval']\n",
    "    other_metrics[f'KNN_4_NN'] = knn_results[nn4[0]]['eval']\n",
    "    other_metrics[f'KNN_8_NN'] = knn_results[nn8[0]]['eval']\n",
    "\n",
    "    # kde = KDEEstimator(baseline_log_edges)\n",
    "    # zero_equiv_uar = 1000 * 0.01 / da_dict[stn]  # 0.01 m3/s to L/s/km2\n",
    "    eval_object = EvaluationMetrics(log_x=station_data.log_x_extended, bitrate=bitrate, min_measurable_log_uar=station_data.min_measurable_log_uar,)\n",
    "    print(f'    Processing FDCs for {stn}')\n",
    "    \n",
    "    years = []\n",
    "    for date in ['20250514', '20250627']:\n",
    "        pmf_columns = []\n",
    "        years = lstm_df.index.year.unique()\n",
    "        da = da_dict[stn]\n",
    "        pmf_folder = Path('data/results/additional_results/lstm_pmfs/')\n",
    "        os.makedirs(pmf_folder) if not os.path.exists(pmf_folder) else None\n",
    "        pmf_file = f'POR_{stn}_pmfs_{len(years)}_years_{date}.csv'\n",
    "        pmf_fpath = pmf_folder / pmf_file\n",
    "\n",
    "        # compute observed POR PMFs \n",
    "        obs_cols = [c for c in lstm_df.columns if c.startswith('streamflow_obs') and c.endswith(date)]\n",
    "        assert len(obs_cols) == 1, f'Expected exactly one observed column for {stn} on {date}, found {len(obs_cols)}'\n",
    "        por_obs_vals = lstm_df[obs_cols[0]].dropna().values\n",
    "        # print(f'{stn} POR obs: {min(por_obs_vals):.2f} - {max(por_obs_vals):.2f}')\n",
    "        # por_obs_pmf, _ = station_data.kde.compute(por_obs_vals, da=da)\n",
    "        por_obs_pmf = station_data.build_pmf_from_timeseries(por_obs_vals, station_data.min_measurable_log_uar, da)\n",
    "        assert len(por_obs_pmf) == len(baseline_log_grid), f'PMF length mismatch for {stn} on {date} ({len(por_obs_pmf)} vs {len(baseline_log_grid)})'\n",
    "        pmf_columns.append(pd.Series(por_obs_pmf, index=baseline_log_grid, name=f'POR_obs_{date}'))\n",
    "\n",
    "        # compute simulated POR PMFs\n",
    "        sim_cols = [c for c in lstm_df.columns if c.startswith('streamflow_sim') and c.endswith(date)]\n",
    "        # temporal mean of the simulated ensemble\n",
    "        sim_vals = lstm_df[sim_cols].mean(axis=1).dropna().values\n",
    "        # sim_pmf, _ = station_data.kde.compute(sim_vals, da=da) # temporal mean ensemble PMF\n",
    "        sim_pmf = station_data.build_pmf_from_timeseries(sim_vals, station_data.min_measurable_log_uar, da)\n",
    "        assert len(sim_pmf) == len(baseline_log_grid), f'PMF length mismatch for {stn} on {date}'\n",
    "        pmf_columns.append(pd.Series(sim_pmf, index=baseline_log_grid, name=f'POR_sim_timeEnsemble_{date}'))\n",
    "\n",
    "        frequency_sim_pmfs = compute_ensemble_pmfs(lstm_df, sim_cols, station_data)\n",
    "        mean_pmf = frequency_sim_pmfs.mean(axis=1).rename('sim_distEnsemble_mean')\n",
    "        mean_pmf /= mean_pmf.sum()  # renormalize the PMF\n",
    "        pmf_columns.append(pd.Series(mean_pmf, index=baseline_log_grid, name=f'POR_sim_distEnsemble_{date}'))\n",
    "\n",
    "        og_vals = og_df[f'{stn}_uar'].dropna().values\n",
    "        # print(f'{stn}_uar: {min(og_vals):.2f} - {max(og_vals):.2f}')\n",
    "        # og_pmf, _ = station_data.kde.compute(og_vals, da=da)\n",
    "        og_pmf = station_data.build_pmf_from_timeseries(og_vals, station_data.min_measurable_log_uar, da)\n",
    "        pmf_columns.append(pd.Series(og_pmf, index=baseline_log_grid, name=f'{stn}_uar'))\n",
    "        por_pmfs = pd.concat(pmf_columns, axis=1)    # do the same for the original timeseries\n",
    "        pmfs = pd.concat([por_pmfs, frequency_sim_pmfs], axis=1)  # initialize PMFs DataFrame with observed PMFs\n",
    "        pmfs.index.name = 'log_uar'  # set the index name for clarity\n",
    "        # save the PMFs to a CSV file\n",
    "        pmfs.to_csv(pmf_fpath)\n",
    "        pmf_dfs[date] = pmfs\n",
    "\n",
    "        # evaluate metrics\n",
    "        for col in [f'POR_sim_timeEnsemble_{date}', f'POR_sim_distEnsemble_{date}']:\n",
    "            pmf = pmfs[col].values\n",
    "            por_metrics[col] = eval_object._evaluate_fdc_metrics_from_pmf(pmf, por_obs_pmf, min_measurable_log_uar=station_data.min_measurable_log_uar)\n",
    "\n",
    "        for col in frequency_sim_pmfs.columns:\n",
    "            pmf = frequency_sim_pmfs[col].values\n",
    "            por_metrics[col] = eval_object._evaluate_fdc_metrics_from_pmf(pmf, por_obs_pmf, min_measurable_log_uar=station_data.min_measurable_log_uar)\n",
    "\n",
    "    mdf = pd.DataFrame(por_metrics).T\n",
    "    odf = pd.DataFrame(other_metrics).T\n",
    "    # save to csv\n",
    "    metric_fpath = f'data/results/lstm_metrics/{stn}_{len(years)}_years_metrics.csv'\n",
    "    mdf.to_csv(metric_fpath)\n",
    "    return mdf, odf, pmf_dfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe813c6-1700-4488-a4a9-5c7aa2089997",
   "metadata": {},
   "source": [
    "### Streamflow monitoring stations that we found to be regulated or influenced by regulation by looking at results plots\n",
    "\n",
    "A number of stations in the large sample were found to be regulated or influenced by regulation by looking at results plots.  These are listed below with notes.  These stations should be excluded from the sample for future analysis unless the particular application calls for time series of regulated streams.\n",
    "\n",
    "* 12398000 - Sullivan Lake upstream is a reservoir\n",
    "* 12058800 - Dam!\n",
    "\n",
    "### Other anomalous conditions\n",
    "\n",
    "* 12143700 -  *Small catchment adjacent to dam* (USGS.gov) No regulation or diversion upstream from station. **Flow is mostly seepage from Chester Morse Lake.** U.S. Geological Survey satellite telemeter at station.  This represnts a very specific scenario that depends upon hydraulic conditions in neighbouring catchments but also the operation policy if the neighbouring catchment contains a large reservoir. \n",
    "* 12143900 -  *Just downstream from 12143700* Heavily affected by the same condition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c6a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_label_styles = {\n",
    "    \"timeEnsemble\":       (\"#2ca25f\", \"white\"),  # green\n",
    "    \"distEnsemble\":       (\"#2ca25f\", \"white\"),\n",
    "    \"LN MLE\":             (\"#fdae6b\", \"black\"),  # orange\n",
    "    \"LN_PredictedLog\":    (\"#fdae6b\", \"black\"),\n",
    "    \"LN_PredictedMOM\":    (\"#fdae6b\", \"black\"),\n",
    "    \"KNN_2_NN\":           (\"#756bb1\", \"white\"),  # purple\n",
    "    \"KNN_4_NN\":           (\"#756bb1\", \"white\"),  # purple\n",
    "    \"KNN_8_NN\":           (\"#756bb1\", \"white\"),\n",
    "}\n",
    "\n",
    "\n",
    "def key_mapper(mod,met):\n",
    "    \n",
    "    if met == 'pct_vol_bias':\n",
    "        met = 'PB'\n",
    "    met = met.upper()\n",
    "    if mod.startswith('time'):\n",
    "        key = f'LSTM time {met}'\n",
    "    elif mod.startswith('dist'):\n",
    "        key = f'LSTM dist. {met}'\n",
    "    elif 'MOM' in mod:\n",
    "        key = f'LN MoM {met}'\n",
    "    elif 'PredictedLog' in mod:\n",
    "        key = f'LN Direct {met}'\n",
    "    elif 'MLE' in mod:\n",
    "        key = f'MLE {met}'\n",
    "    elif mod.endswith('_NN'):\n",
    "        k = mod.split('_')[1]\n",
    "        key = f'{k} kNN {met}'\n",
    "    else:\n",
    "        raise Exception(f'{mod} {met} combo not found')\n",
    "    return key\n",
    "\n",
    "\n",
    "def plot_runoff_timeseries(stn, lstm_df, og_df, date):\n",
    "\n",
    "    obs_col = [c for c in lstm_df.columns if '_obs_' in c and c.endswith(date)]\n",
    "    assert len(obs_col) == 1, f'Expected exactly one observed column for {stn}, found {len(obs_col)} {obs_col}'\n",
    "    sim_cols = [c for c in lstm_df.columns if c.startswith('streamflow_sim') and c.endswith(date)]\n",
    "    assert len(sim_cols) == 10, f'Expected ten simulation columns for {stn}, found {len(sim_cols)}'\n",
    "    # plot th time series of the observed values\n",
    "    runoff_plot = figure(title=f'{stn} Observed Unit Area Runoff', x_axis_type='datetime',\n",
    "                         width=1000, height=300, y_axis_type='log', toolbar_location='above')\n",
    "    \n",
    "    hydat_df = query_hydat_database(stn)\n",
    "    quality_symbols = query_data_symbols(stn)\n",
    "\n",
    "    # reindex to daily frequency and keep nans\n",
    "    df = lstm_df.copy().reindex(pd.date_range(start=lstm_df.index.min(), end=lstm_df.index.max(), freq='D'))\n",
    "    og_df['zero_flow_flag'] = False\n",
    "\n",
    "    if (not hydat_df.empty) & (not quality_symbols.empty):\n",
    "        runoff_plot = plot_quality_flag_periods(stn, df, hydat_df, quality_symbols, runoff_plot, obs_col)\n",
    "\n",
    "    # plot zero flow segments on the runoff_plot\n",
    "    runoff_plot = plot_zero_flow_periods(stn, og_df, runoff_plot, obs_col)\n",
    "    # plot the adjusted line\n",
    "    runoff_plot.line(df.index, df[obs_col[0]], color='dodgerblue',\n",
    "                     legend_label='Observed UAR', line_width=2.)\n",
    "    for col in sim_cols:\n",
    "        runoff_plot.line(df.index, df[col], color='grey', alpha=0.5,\n",
    "                         legend_label=f'LSTM ensemble')\n",
    "    # compute the temporal mean of the simulated ensemble\n",
    "    mean_sim = df[sim_cols].mean(axis=1)\n",
    "    runoff_plot.line(df.index, mean_sim, color='green', legend_label='Ensemble Mean', line_width=3, line_dash='dashed')\n",
    "    runoff_plot.xaxis.axis_label = 'Date'\n",
    "    runoff_plot.yaxis.axis_label = 'Unit Area Runoff (L/s/km2)'\n",
    "    runoff_plot.legend.location = 'top_left'\n",
    "    runoff_plot.legend.click_policy = 'hide'\n",
    "    runoff_plot.add_layout(runoff_plot.legend[0], 'right')\n",
    "    runoff_plot.legend.background_fill_alpha = 0.65\n",
    "    return runoff_plot\n",
    "    \n",
    "\n",
    "def format_metrics_table(metric_df, odf, stn, date, fdc_metrics):\n",
    "    # Prep LSTM metrics\n",
    "    metric_df.index.name = 'series'\n",
    "    metric_df = metric_df.reset_index()\n",
    "    \n",
    "    lstm_df = metric_df[metric_df['series'].str.endswith(date)].copy()\n",
    "    metric_cols = [c for c in lstm_df.columns if c not in ['series', 'date']]    \n",
    "    time_df = lstm_df[lstm_df['series'].str.contains('timeEnsemble')][metric_cols]\n",
    "    freq_df = lstm_df[lstm_df['series'].str.contains('distEnsemble')][metric_cols]\n",
    "    # sim_df = lstm_df[lstm_df['series'].str.startswith('streamflow_sim_')][metric_cols]\n",
    "    # sim_perc = pd.DataFrame(np.percentile(sim_df.values, [5, 95], axis=0), index=['5%', '95%'], columns=metric_cols)\n",
    "    \n",
    "    table = pd.concat([time_df, freq_df])#, sim_perc])\n",
    "    table.index = ['timeEnsemble', 'distEnsemble']#, '5%', '95%']\n",
    "\n",
    "    # \"pct_vol_bias\": float(pct_vol_bias), # this is PBIAS (labeled RB in some notebooks)\n",
    "    # \"mean_abs_pct_error\": float(mean_abs_pct_error), # this is MAPE\n",
    "    # \"norm_abs_error\": float(np.mean(norm_abs_err)),\n",
    "    # \"rmse\": float(rmse), \n",
    "    # \"nse\": float(nse), \n",
    "    # \"kge\": float(kge),\n",
    "    # \"ve\": float(ve),\n",
    "    # \"pb_50\": float(pinball_loss_50),\n",
    "    # \"kld\": float(kld),\n",
    "    # \"emd\": float(emd),\n",
    "    \n",
    "    # Prep ODF\n",
    "    mapper = {'pct_vol_bias': 'pb', 'mean_abs_pct_error': 'mape',\n",
    "              'norm_abs_error': 'nae', }\n",
    "    odf = odf.rename(columns=mapper)\n",
    "    table = table.rename(columns=mapper)\n",
    "\n",
    "    max_cols = ['nse', 'kge', 've']\n",
    "    min_abs_cols = ['pb', 'mape', 'nae',]\n",
    "\n",
    "    # Combine and compute percentiles\n",
    "    df = pd.concat([table, odf], axis=0)\n",
    "\n",
    "    # df.drop(labels=['median_error'], axis=1, inplace=True)\n",
    "        \n",
    "    colors = [\n",
    "        \"#2166ac\", \"#4393c3\", \"#92c5de\", \"#d1e5f0\", \"#f7f7f7\",\n",
    "        \"#fddbc7\", \"#f4a582\", \"#d6604d\", \"#b2182b\", \"#67001f\"\n",
    "    ]\n",
    "    # Build HTML table with row labels\n",
    "    html = '<table style=\"width:100%; border-collapse:collapse; margin-top:25px;\">'\n",
    "    html += '<thead><tr>'\n",
    "    table_cols = {'pb': 'PB', 'mape': 'MAPE', 'nae': 'NAE'}\n",
    "    col_order = ['pb', 'nae', 'mape', 'rmse', 'kld', 'emd', 'nse', 'kge']#, 'pmf', 'fdc']\n",
    "    # 'rb', 'mb', 'mean_abs_rel_error', 'rmse', 'nse', 'kge', 've', 'pb_50',\n",
    "    #    'kld', 'emd']\n",
    "    df = df[col_order]\n",
    "    for c in df.columns:\n",
    "        label = c\n",
    "        if c in table_cols:\n",
    "            label = table_cols[c]\n",
    "        html += f'<th>{label}</th>'\n",
    "\n",
    "    html += '<th style=\"text-align:left;\">Model</th></tr></thead><tbody>'\n",
    "    \n",
    "    for model, row in df.iterrows():\n",
    "        html += f'<tr>'\n",
    "        for metric in df.columns:\n",
    "            val = df.at[model, metric]\n",
    "\n",
    "            key = key_mapper(model, metric)\n",
    "            assert key in all_results_df.columns, f'{key} not found in allresults df columns: {list(all_results_df.columns)}'\n",
    "            \n",
    "            global_vals = all_results_df[key].dropna().values\n",
    "            assert not len(global_vals) == 0, f'Global vals is empty: key={key}, {list(all_results_df.columns)}' \n",
    "            minv, maxv = np.min(global_vals), np.max(global_vals)\n",
    "            \n",
    "            if metric in min_abs_cols:\n",
    "                rank = np.searchsorted(np.sort(np.abs(global_vals)), abs(val), side=\"right\")\n",
    "            else:\n",
    "                global_vals = np.sort(global_vals)\n",
    "                rank = np.searchsorted(global_vals, val, side=\"right\")\n",
    "            \n",
    "            pct = rank / len(global_vals)\n",
    "            if metric in max_cols:\n",
    "                pct = 1 - pct\n",
    "            idx = min(math.floor(pct * 10), 9)\n",
    "            bg = colors[idx]\n",
    "            font = \"white\" if idx in {0, 1, 8, 9} else \"black\"\n",
    "            \n",
    "            # html += f'<td style=\"background:{color};text-align:center;\"><span style=\"color:{font};\">{row[c]:.2f}</span></td>'\n",
    "            html += f'<td style=\"background:{bg}; text-align:center; padding:4px 6px;\"><span style=\"color:{font};\">{row[metric]:.2f}</span></td>'\n",
    "        \n",
    "        row_bg, row_font = model_label_styles.get(model, (\"#ffffff\", \"black\"))\n",
    "        html += f'<td style=\"background:{row_bg}; color:{row_font}; text-align:left; font-weight:bold;padding:4px 4px;\">{model}</td>'\n",
    "        # html += f'<td style=\"text-align:left; font-weight:bold; padding:4px 4px;\">{model}</td>'\n",
    "    html += '</tbody></table>'\n",
    "    # Add color legend\n",
    "    legend_html = '<table style=\"border-collapse:collapse; margin-bottom:4px;\"><caption>Rank percentile colour map (N=720):</caption><tr>'\n",
    "    for i, color in enumerate(colors):\n",
    "        pct_label = f\"{(i+1)*10}%\"\n",
    "        font = \"white\" if i in {0, 1, 8, 9} else \"black\"\n",
    "        legend_html += f'<td style=\"background:{color}; padding:4px 4px; text-align:center;\"><span style=\"color:{font}\">{pct_label}</span></td>'\n",
    "    legend_html += '</tr></table>'\n",
    "\n",
    "    return Div(text=html), Div(text=legend_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5df24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stn = '12143900'\n",
    "# og_df = get_original_timeseries(stn, ds)\n",
    "# lstm_ensemble_df = filter_by_complete_years(stn, lstm_result_base_folder)\n",
    "# # boxley_df = retrieve_timeseries_discharge('12143700', ds)\n",
    "# boxley_df = retrieve_timeseries_discharge('12143900', ds)\n",
    "# # fig = figure(width=800, height=350, x_axis_type='datetime')\n",
    "# # fig.line(boxley_df.index, boxley_df['12143700_uar'], line_width=2, color='blue', legend_label='Boxley Creek UAR')\n",
    "# date = '20250514'\n",
    "# ts = plot_runoff_timeseries(stn, lstm_ensemble_df, og_df, date)\n",
    "# ts.line(boxley_df.index, boxley_df['12143900_uar'], line_width=2, color='purple',\n",
    "#         line_dash='dashed', legend_label='12143900 UAR')\n",
    "# # change the legend labels\n",
    "# # Rename a legend label\n",
    "# for legend in ts.legend:\n",
    "#     for item in legend.items:\n",
    "#         if item.label['value'] == \"Observed UAR\":\n",
    "#             print(item.label)\n",
    "#             item.label.value = \"12143700 UAR\"\n",
    "#             # item.label['value'] = \"12143700 UAR\"\n",
    "#             # break # Exit inner loop once found\n",
    "#         elif item.label['value'] == \"Observed UAR\":\n",
    "#             item.label.value = \"12143900 UAR\"\n",
    "#             # item.label['value'] = \"12143900 UAR\"\n",
    "#             # break # Exit inner loop once found\n",
    "\n",
    "# show(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de850a2a",
   "metadata": {},
   "source": [
    "Above we can see the simulated flows are dramatically different from observed. As it turns out, this catchment is heavily influenced by seepage from Chester Morse Lake, which is a reservoir on the adjacent catchment.  The flow here is not natural and depends upon hydraulic conditions in the neighbouring catchment but also the reservoir operation policy.  This represents a very specific scenario that is not representative of most catchments and should be excluded from the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb23fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_diagnostic_plot_layout(stn_data):\n",
    "    output_folder = BASE_DIR / 'data' / 'results' /  'lstm_plots'\n",
    "    result_folder = BASE_DIR / 'data' / 'results' / f'fdc_estimation_results_{bitrate:02d}_bits'\n",
    "    if regularization_type == 'kde':\n",
    "        result_folder = BASE_DIR / 'data' / 'results' /'fdc_estimation_results_kde'\n",
    "\n",
    "    stn = stn_data.target_stn\n",
    "    og_df = stn_data.hyd_df.copy()\n",
    "    lstm_ensemble_df = filter_LSTM_outputs(stn_data, lstm_result_base_folder)\n",
    "\n",
    "    if lstm_ensemble_df.empty:\n",
    "        print(f'No complete years found for {stn}. Skipping.')\n",
    "        return Div(text=f'<h2>Insufficient records found for {stn}. Skipping.</h2>', width=800)\n",
    "    \n",
    "    og_df = og_df[og_df.index.isin(lstm_ensemble_df.index)]\n",
    "    mdf, odf, pmf_dfs = process_FDCs(stn, og_df, lstm_ensemble_df, result_folder, stn_data)\n",
    "\n",
    "    dates = list(pmf_dfs.keys())\n",
    "    pdf_plots, fdc_plots, metric_tables, other_tables = [], [], [], []\n",
    "    date = '20250514'\n",
    "    \n",
    "    pdf_plot, baseline_log_grid, baseline_lin_grid, log_w = plot_observed_and_simulated_pdf(stn, pmf_dfs, og_df, date, stn_data, pdf_plots=pdf_plots)\n",
    "    pdf_plots.append(pdf_plot)\n",
    "\n",
    "    min_measurable = stn_data.min_measurable_uar\n",
    "    assert min_measurable < 1e3, f'Min measurable UAR too high: {min_measurable}'\n",
    "    \n",
    "    fdc_plot, fdc_metrics = plot_observed_and_simulated_fdc(stn, pmf_dfs, baseline_lin_grid, lstm_ensemble_df, og_df, date, stn_data, fdc_plots=fdc_plots)\n",
    "    fdc_plots.append(fdc_plot)\n",
    "    \n",
    "    ts_plot = plot_runoff_timeseries(stn, lstm_ensemble_df, og_df, dates[-1])\n",
    "    \n",
    "    metric_table, legend_html = format_metrics_table(mdf, odf, stn, date, fdc_metrics)\n",
    "\n",
    "    table_div = column(\n",
    "        metric_table,\n",
    "        legend_html,\n",
    "    )\n",
    "    notes_div = Div(text=notes_html, width=1000)\n",
    "    layout = column(\n",
    "        row(fdc_plots[0], table_div),\n",
    "        row(ts_plot), \n",
    "        row(pdf_plots[0]),\n",
    "        row(notes_div),\n",
    "        )\n",
    "    return layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a206777",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_min_uar = 5e-5   # see Notebook 1: data\n",
    "global_max_uar = 1e4    # see Notebook 1: data\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "target_cols = [\n",
    "    'mean_uar', 'sd_uar', \n",
    "    'mean_logx', 'sd_logx', \n",
    "]\n",
    "\n",
    "regularization_type = 'discrete'#'kde'  # 'discrete' or 'kde'\n",
    "# bitrate = 10 if regularization_type == 'discrete' else 10\n",
    "\n",
    "# set paths for catchment attributes and meteorological forcing data\n",
    "attr_df_fpath = os.path.join('data', f'catchment_attributes_with_runoff_stats.csv')\n",
    "LSTM_forcings_folder = '/home/danbot/neuralhydrology/data/BCUB_catchment_mean_met_forcings_20250320'\n",
    "baseline_distribution_folder = os.path.join('data', 'baseline_distributions', f'{bitrate:02d}_bits')\n",
    "# parameter_prediction_results_folder = os.path.join('data', 'parameter_prediction_results')\n",
    "\n",
    "parameter_prediction_results_folder = os.path.join('data', 'results', 'parameter_prediction_results', )\n",
    "predicted_params_fpath   = os.path.join(parameter_prediction_results_folder, 'OOS_parameter_predictions.csv')\n",
    "rdf = pd.read_csv(predicted_params_fpath, index_col=['official_id'], dtype={'official_id': str})\n",
    "predicted_param_dict = rdf.to_dict(orient='index')\n",
    "\n",
    "# load the pre-computed dictionary of complete years of record for each station\n",
    "complete_year_stats_fpath = os.path.join('data', 'complete_year_stats.npy')\n",
    "complete_year_stats = np.load(complete_year_stats_fpath, allow_pickle=True).item()\n",
    "\n",
    "meet_min_hyd_years = []\n",
    "for stn in complete_year_stats.keys():\n",
    "    if len(complete_year_stats[stn]['hyd_years']) >= 5:\n",
    "        meet_min_hyd_years.append(stn)\n",
    "    else:\n",
    "        print(f'Station {stn} has {len(complete_year_stats[stn][\"hyd_years\"])} complete hydrological years of data.')\n",
    "\n",
    "# set which (subset of) methods to run\n",
    "methods = ('knn','parametric', 'lstm',)\n",
    "k_nearest = 10\n",
    "include_pre_1980_data = True  # use only stations with data 1980-present concurrent with Daymet\n",
    "daymet_start_date = '1980-01-01'  # default start date for Daymet data\n",
    "if include_pre_1980_data:\n",
    "    daymet_start_date = '1950-01-01'\n",
    "\n",
    "\n",
    "input_data = {\n",
    "    'attr_df_fpath': attr_df_fpath,\n",
    "    'LSTM_forcings_folder': LSTM_forcings_folder,\n",
    "    'LSTM_ensemble_result_folder': LSTM_ensemble_result_folder,\n",
    "    'include_pre_1980_data': include_pre_1980_data,  # use only stations with data 1980-present concurrent with Daymet\n",
    "    'predicted_param_dict': predicted_param_dict,\n",
    "    'eps': 1e-12,\n",
    "    'min_record_length': 5, # minimum record length (years)\n",
    "    'minimum_days_per_month': 20, # minimum number of days with valid data per month\n",
    "    'parametric_target_cols': target_cols,\n",
    "    'all_station_ids': daymet_concurrent_stations,\n",
    "    'baseline_distribution_folder': baseline_distribution_folder,\n",
    "    'delta': 0.001, # maximum uncertainty (by KL divergence) added to the predicted PMF by the uniform mixture ratio\n",
    "    'regularization_type': regularization_type, # use 'kde' or 'discrete'.  if discrete, bitrate must be specified\n",
    "    'bitrate': bitrate,\n",
    "    'complete_year_stats': complete_year_stats,\n",
    "    'year_type': 'hydrological',  # 'calendar' or 'hydrological'\n",
    "    'zero_flow_threshold': 1e-4,  # threshold below which flow is indistinguishable from zero\n",
    "    'global_min_uar': global_min_uar,\n",
    "    'global_max_uar': global_max_uar,\n",
    "}\n",
    "\n",
    "context = FDCEstimationContext(**input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd4d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve LSTM ensemble predictions\n",
    "# filter for the common stations\n",
    "common_stations = list(set(station_ids) & set(lstm_result_stns))\n",
    "stations_to_process = ['08AA008', '12090500', '12102190', '12115700', '12115800',\n",
    "       '12157025', '12201960', '10CD003', '10CD004', '12447383',\n",
    "       '08HB075', '10ED009', '08HA026', '12202310', '10CD005', '12202420',\n",
    "       '12210900', '12193500', '12036650', '07BB003']\n",
    "\n",
    "# print(f'There are {len(common_stations)} monitored basins with LSTM ensemble results.')\n",
    "attr_df = attr_df[attr_df['official_id'].isin(stations_to_process)]\n",
    "\n",
    "output_folder = BASE_DIR / 'data' / 'results' /  'lstm_plots'\n",
    "# result_folder = BASE_DIR / 'data' / 'results' / f'fdc_estimation_results_{bitrate:02d}_bits'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "processed_kde_folder = 'data/results/fdc_estimation_results_kde/knn'\n",
    "processed_kde_result_files = [e.split('_')[0] for e in os.listdir(processed_kde_folder)]\n",
    "\n",
    "\n",
    "# plots = []\n",
    "excluded = ['12137800'] \n",
    "dam_sites = ['12398000', '12058800', '12143700', '12323760'] \n",
    "to_check = ['05BF018']\n",
    "process_plots = True\n",
    "if process_plots:\n",
    "    for stn in processed_kde_result_files:\n",
    "        # if os.path.exists(output_fname):\n",
    "        #     print(f'Plot for {stn} already exists at {output_fname}. Skipping.')\n",
    "        #     continue\n",
    "        # save the plot to an HTML file\n",
    "        if regularization_type == 'kde':\n",
    "            output_fname = output_folder / f'{stn}_fdc_kde.html'\n",
    "        else:\n",
    "            output_fname = output_folder / f'{stn}_fdc_{bitrate:02d}_bits.html'\n",
    "        if stn not in context.attr_gdf['official_id'].values:\n",
    "            continue\n",
    "        station_data = StationData(context, stn)\n",
    "        station_data.kde = KDEEstimator(station_data.log_edges_extended)\n",
    "        if stn in dam_sites:\n",
    "            continue\n",
    "        if stn in excluded:\n",
    "            continue\n",
    "        # if os.path.exists(output_fname):\n",
    "        #     print(output_fname)\n",
    "        #     continue\n",
    "        layout = process_diagnostic_plot_layout(station_data)\n",
    "\n",
    "        output_file(output_fname, title=f'{stn} FDCs')\n",
    "        save(layout)\n",
    "        print(f'    Saved plot for {stn} to {output_fname}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d76e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e424d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a4edd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876b427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
