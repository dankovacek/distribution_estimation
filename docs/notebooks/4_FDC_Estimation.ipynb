{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a180e32",
   "metadata": {},
   "source": [
    "# FDC Estimation\n",
    "\n",
    "This notebook contains the main code for computing FDCs by the different methods. \n",
    "\n",
    "It requires the runoff statistics to have been computed, and the results of the XGBoost prediction model (catchment attributes $\\rightarrow$ hydrologic signatures / runoff statistics) to have been processed in Notebook 3.  It also requires the pre-processing of reference (baseline) distributions by KDE for validation from Notebook 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "558cd32f-b562-4502-ab63-826aede8f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from time import time\n",
    "import geopandas as gpd\n",
    "\n",
    "import xgboost as xgb\n",
    "xgb.config_context(verbosity=2)\n",
    "\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from utils.kde_estimator import KDEEstimator\n",
    "from utils.knn_estimator import kNNEstimator\n",
    "from utils.LSTM_estimator import LSTMFDCEstimator\n",
    "from utils.parametric_estimator import ParametricFDCEstimator\n",
    "from utils.fdc_estimator_context import FDCEstimationContext \n",
    "from utils.fdc_data import StationData\n",
    "from utils.evaluation_metrics import EvaluationMetrics\n",
    "\n",
    "import utils.data_processing_functions as dpf\n",
    "\n",
    "from pathlib import Path\n",
    "BASE_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1356ccc6-3d6d-4e08-bdbc-53a798187d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"f8c0af6e-7868-4bd6-8e6f-32acfe65b4d7\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"f8c0af6e-7868-4bd6-8e6f-32acfe65b4d7\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.8.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.8.0.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"f8c0af6e-7868-4bd6-8e6f-32acfe65b4d7\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "import xyzservices.providers as xyz\n",
    "tiles = xyz['USGS']['USTopo']\n",
    "output_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "894b3bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1017 monitored basins in the attribute set.\n"
     ]
    }
   ],
   "source": [
    "# load the catchment characteristics\n",
    "fname = f'catchment_attributes_with_runoff_stats.csv'\n",
    "attr_df = pd.read_csv(os.path.join('data', fname), dtype={'official_id': str, 'drainage_area_km2': float})\n",
    "attr_df.columns = [c.lower() for c in attr_df.columns]\n",
    "attr_df['log_drainage_area_km2'] = np.log(attr_df['drainage_area_km2'])\n",
    "# attr_df = attr_df[~attr_df['official_id'].isin(exclude)]\n",
    "# attr_df.columns = [c.lower() for c in attr_df.columns]\n",
    "attr_df['tmean'] = (attr_df['tmin'] + attr_df['tmax']) / 2.0\n",
    "station_ids = attr_df['official_id'].values\n",
    "stn_da_dict = attr_df.set_index('official_id')['drainage_area_km2'].to_dict()\n",
    "# assert '12414900' in station_ids\n",
    "\n",
    "print(f'There are {len(station_ids)} monitored basins in the attribute set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b463650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Watershed_ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Name</th>\n",
       "      <th>Official_ID</th>\n",
       "      <th>Centroid_Lat_deg_N</th>\n",
       "      <th>Centroid_Lon_deg_E</th>\n",
       "      <th>Drainage_Area_km2</th>\n",
       "      <th>Drainage_Area_GSIM_km2</th>\n",
       "      <th>Flag_GSIM_boundaries</th>\n",
       "      <th>Flag_Artificial_Boundaries</th>\n",
       "      <th>...</th>\n",
       "      <th>Land_Use_Wetland_frac</th>\n",
       "      <th>Land_Use_Water_frac</th>\n",
       "      <th>Land_Use_Urban_frac</th>\n",
       "      <th>Land_Use_Shrubs_frac</th>\n",
       "      <th>Land_Use_Crops_frac</th>\n",
       "      <th>Land_Use_Snow_Ice_frac</th>\n",
       "      <th>Flag_Land_Use_Extraction</th>\n",
       "      <th>Permeability_logk_m2</th>\n",
       "      <th>Porosity_frac</th>\n",
       "      <th>Flag_Subsoil_Extraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>847</td>\n",
       "      <td>HYDAT</td>\n",
       "      <td>CROWSNEST RIVER AT FRANK</td>\n",
       "      <td>05AA008</td>\n",
       "      <td>49.59732</td>\n",
       "      <td>-114.4106</td>\n",
       "      <td>402.6522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.0785</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>1</td>\n",
       "      <td>-15.543306</td>\n",
       "      <td>0.170479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>850</td>\n",
       "      <td>HYDAT</td>\n",
       "      <td>CASTLE RIVER NEAR BEAVER MINES</td>\n",
       "      <td>05AA022</td>\n",
       "      <td>49.48866</td>\n",
       "      <td>-114.1444</td>\n",
       "      <td>820.6510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.1156</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>-15.929747</td>\n",
       "      <td>0.150196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Watershed_ID Source                            Name Official_ID  \\\n",
       "846           847  HYDAT        CROWSNEST RIVER AT FRANK     05AA008   \n",
       "849           850  HYDAT  CASTLE RIVER NEAR BEAVER MINES     05AA022   \n",
       "\n",
       "     Centroid_Lat_deg_N  Centroid_Lon_deg_E  Drainage_Area_km2  \\\n",
       "846            49.59732           -114.4106           402.6522   \n",
       "849            49.48866           -114.1444           820.6510   \n",
       "\n",
       "     Drainage_Area_GSIM_km2  Flag_GSIM_boundaries  Flag_Artificial_Boundaries  \\\n",
       "846                     NaN                     0                           0   \n",
       "849                     NaN                     0                           0   \n",
       "\n",
       "     ...  Land_Use_Wetland_frac  Land_Use_Water_frac  Land_Use_Urban_frac  \\\n",
       "846  ...                 0.0103               0.0065               0.0328   \n",
       "849  ...                 0.0058               0.0023               0.0105   \n",
       "\n",
       "     Land_Use_Shrubs_frac  Land_Use_Crops_frac  Land_Use_Snow_Ice_frac  \\\n",
       "846                0.0785               0.0015                  0.0002   \n",
       "849                0.1156               0.0246                  0.0000   \n",
       "\n",
       "     Flag_Land_Use_Extraction  Permeability_logk_m2  Porosity_frac  \\\n",
       "846                         1            -15.543306       0.170479   \n",
       "849                         1            -15.929747       0.150196   \n",
       "\n",
       "     Flag_Subsoil_Extraction  \n",
       "846                        1  \n",
       "849                        1  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# streamflow folder from (updated) HYSETS\n",
    "HYSETS_DIR = Path('/home/danbot/code/common_data/HYSETS')\n",
    "# STREAMFLOW_DIR = HYSETS_DIR / 'streamflow'\n",
    "\n",
    "hs_df = pd.read_csv('data/HYSETS_watershed_properties.txt', sep=';', dtype={'Official_ID': str})\n",
    "hs_df = hs_df[hs_df['Official_ID'].isin(station_ids)]\n",
    "hs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54a492f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1016\n"
     ]
    }
   ],
   "source": [
    "# load the baseline PMFs from the previous notebook\n",
    "pmf_path = Path(os.getcwd()) / 'data' / 'results' / 'baseline_distributions' / f'pmf_kde.csv'\n",
    "pmf_df = pd.read_csv(pmf_path, index_col=0)\n",
    "pmf_stations = pmf_df.columns\n",
    "station_ids = list(set(station_ids).intersection(set(pmf_stations)))\n",
    "print(len(station_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8da5b67-fe95-4d78-94b1-c79ab46c48a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude catchments found to be regulated (missed by QC)\n",
    "# 12143700 isnot actually a dam, it's just basically a seepage monitoring station\n",
    "# from a small catchment next to a dam \n",
    "dam_sites = ['12398000', '12058800', '12143700', '12323760'] # 12143700 - Boxley creek is a really interesting case!\n",
    "official_ids_to_include = [s for s in pmf_stations if s not in dam_sites]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6751a465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 12398000 is in LSTM results but not in the station attributes.\n",
      "Warning: 12143900 is in LSTM results but not in the station attributes.\n",
      "Warning: 12137800 is in LSTM results but not in the station attributes.\n",
      "Warning: 12414900 is in LSTM results but not in the station attributes.\n",
      "Warning: 15056030 is in LSTM results but not in the station attributes.\n",
      "Warning: 12143700 is in LSTM results but not in the station attributes.\n",
      "Warning: 12102190 is in LSTM results but not in the station attributes.\n",
      "Warning: 12058800 is in LSTM results but not in the station attributes.\n",
      "Warning: 12100000 is in LSTM results but not in the station attributes.\n",
      "Warning: 12323760 is in LSTM results but not in the station attributes.\n",
      "There are 1020 monitored basins with baseline PMFs.\n",
      "There are 715 monitored basins concurrent with LSTM ensemble results.\n"
     ]
    }
   ],
   "source": [
    "# retrieve LSTM ensemble predictions\n",
    "LSTM_ensemble_result_folder = '/home/danbot/code/neuralhydrology/data/ensemble_results_20250514' # based on mean NSE loss\n",
    "# LSTM_ensemble_result_folder = '/home/danbot/code/neuralhydrology/data/ensemble_results_20250627' # based on 95% NSE loss\n",
    "lstm_result_files = os.listdir(LSTM_ensemble_result_folder)\n",
    "lstm_result_stns = [e.split('_')[0] for e in lstm_result_files]\n",
    "assert '12414900' in lstm_result_stns\n",
    "\n",
    "# find any non-matching station ids in the lstm result files\n",
    "stns_to_remove_from_lstm_set = []\n",
    "for stn in lstm_result_stns:\n",
    "    if stn not in station_ids:\n",
    "        # try adding a leading zero\n",
    "        ending_in = [e for e in station_ids if e.endswith(stn)]\n",
    "        if len(ending_in) > 0:\n",
    "            print(stn, 'matches', ending_in)\n",
    "        modified_stn = stn.zfill(8)\n",
    "        if modified_stn in station_ids:\n",
    "            print(f'Found modified station id: {modified_stn} for {stn}')\n",
    "        else:\n",
    "            print(f'Warning: {stn} is in LSTM results but not in the station attributes.')\n",
    "            stns_to_remove_from_lstm_set.append(stn)\n",
    "\n",
    "# filter for the common stations between BCUB region and LSTM-compatible (i.e. 1980-)\n",
    "daymet_concurrent_stations = list(set(station_ids) & set(lstm_result_stns) & set(official_ids_to_include))\n",
    "# assert '12414900' in daymet_concurrent_stations\n",
    "print(f'There are {len(pmf_stations)} monitored basins with baseline PMFs.')\n",
    "print(f'There are {len(daymet_concurrent_stations)} monitored basins concurrent with LSTM ensemble results.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f36bb2e9-6a2c-452d-af42-aa49ea32d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple check to make sure \"DAM\" is not in the station name \n",
    "#  -- commonly used to indicate regulated stations\n",
    "for stn in pmf_stations:\n",
    "    hs_data = hs_df[hs_df['Official_ID'] == stn].copy()\n",
    "    name = hs_data['Name']\n",
    "    if 'DAM' in name:\n",
    "        print(stn, name)\n",
    "    if 'RESERVOIR' in name:\n",
    "        print(stn, name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6f0e6e-e089-4951-a047-e0b49b6410c1",
   "metadata": {},
   "source": [
    "## Non-Parametric Simulation\n",
    "\n",
    "### Time-based ensemble\n",
    "\n",
    "A probability distribution $\\hat p = f(\\tilde x(t))$ is estimated for a target (ungauged location) by a weighted mean of runoff time-series from k nearest neighbour stations, $\\tilde x(t) = \\textbf{X}(t)\\cdot w$ where $X(t) \\in \\mathbb{R}^{N \\times k}$ and $w \\in \\mathbb{R}^{k\\times 1}$ is a vector of k weights.  So $\\hat p = f(\\textbf{X}(t) \\cdot w )$  Weights $w$ are computed in three ways, described in the next subsection, and k-nearest neighbours are selected using the criteria defined below.  Each gauged station in the monitoring network is treated as an ungauged location to generate a large sample of simulations across hydrologically diverse catchments, or rather as many catchments as can be tested.\n",
    "\n",
    "### Frequency-based ensembles\n",
    "\n",
    "A simulated probability density function is estimated from observations of k nearest neighbour stations.  First, k simulated series are generated by equal unit area runoff , $\\hat p = \\hat P \\cdot w$ where $\\hat P = [\\hat p_1, \\hat p_2, \\cdots, \\hat p_k]$ and each $\\hat p_i = f(X_i(t))$.\n",
    "\n",
    "In both cases, the function $f \\rightarrow \\hat p(x)$ represents kernel density estimation, which defines the probability density as $$\\hat p(x) = \\frac{1}{n \\cdot h(x)} \\sum_{i=1}^{n}K\\left( \\frac{x-x_i}{h(x)}\\right)$$ \n",
    "\n",
    "Where $h(x)$ reflects an adaptive kernel bandwidth that addresses vestiges of precision in the observed data to reflect the nature of streamflow as a continuous variable, and additionally incorporates piecewise linear model to represent overall measurement uncertainty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7d4695",
   "metadata": {},
   "source": [
    "## Notes on k-nearest neighbours\n",
    "\n",
    "Time series streamflow records vary widely in their temporal coverage, and finding k-nearest neighbours presents a tradeoff between selecting nearest neighbours and maximizing the number of observations concurrent with the target.  From the literature, concurrency is assured by pre-selecting a subset of stations with continuous records over a common period of record, or by infilling gaps with k-nearest neighbours simulation.  Some kind of tradeoff must be made, and we aim to use a method that maximizes information content while minimizing the number of assumptions.  The following notes are intended to clarify the implications of using k-nearest neighbours to fill gaps in the time series.\n",
    "\n",
    "1. **Infilled-by-kNN != Independent Proxy**: If a gap in an observation record is inferred from neighbors, it becomes redundant in the ensemble and increases the weight of the other (k minus n) neighbours.  So at that time step, its influence is non-unique, and including it in the ensemble is functionally equivalent to using the same set of other proxies directly, or just reducing the ensemble size.\n",
    "\n",
    "2. **Inflated Ensemble Size**: Filling gaps by \"nested\" k-nearest neighbours inflates the expresed number of independent neighbors.  Comparing the effectiveness of ensemble simulations as a function of k is then misleading because the effective number of independent proxies is *at most* k. \n",
    "\n",
    "3. **Information leakage risk**: If you repeatedly use kNN to fill missing data from within the same pool, especially when simulating extreme values, you risk suppressing variability by biasing toward the central tendency of the ensemble.  This defeats one of the core motivations for kNN: to preserve structure and variability from observations at neighboring stations.\n",
    "\n",
    "To address the nuance above, we propose three time-based methods for selecting k-nearest neighbours beyond strictly nodes in the network.  The problem is related to the set-cover problem where the goal is to select a subset of stations that maximizes the intersection of their data availability over a specified time period.  The following sections outline the three methods for selecting k-nearest neighbours based on availability of concurrent data.\n",
    "\n",
    "### Summary: Set-Theoretic implications of strict k-NN concurrency selection\n",
    "\n",
    "This problem is closely related to classic combinatorial and set-theoretic optimization problems.\n",
    "\n",
    "#### Set-Theoretic Definition\n",
    "\n",
    "Let each column $( S_i \\subseteq T )$ represent the set of timestamps where station $( i )$ has valid (non-NaN) data.  \n",
    "Let $( \\mathcal{S} = \\{ S_1, S_2, \\dots, S_n \\} )$ be the collection of all such subsets, sorted by proximity (e.g., distance or attribute similarity).  \n",
    "The goal is to select a subset $( \\mathcal{K} \\subset \\mathcal{S} )$ such that:\n",
    "- $( |\\mathcal{K}| = k )$\n",
    "- $( \\bigcap_{S \\in \\mathcal{K}} S )$ satisfies a temporal completeness constraint (e.g., ≥5 years with ≥10 observations in each of 12 months)\n",
    "\n",
    "This is a constrained subset selection problem on the intersection of sets.\n",
    "\n",
    "#### Related Concepts\n",
    "\n",
    "| Concept                                 | Description |\n",
    "|----------------------------------------|-------------|\n",
    "| Set Intersection Selection             | Select \\( k \\) sets whose intersection satisfies a completeness constraint. |\n",
    "| Maximum Coverage under Cardinality Constraint | Choose \\( k \\) sets to maximize the coverage (or completeness) of their intersection. |\n",
    "| Recursive k-Subset Validation          | If the initial \\( k \\) sets fail, iteratively add more candidates and evaluate all \\( \\binom{k+1}{k} \\) combinations, and so on. |\n",
    "| NP-Hard Nature                         | This problem is computationally hard and shares structure with the Set Cover and Maximum Coverage problems. |\n",
    "\n",
    "#### Practical Implication\n",
    "\n",
    "This formulation justifies using greedy or approximate subset selection strategies when exhaustively testing all combinations becomes computationally infeasible.\n",
    "## Define a universal parametric prior\n",
    "\n",
    "In order to fairly test how parametric and non-parametric pdf estimation methods compare to each other, we need a consistent way to deal with indeterminate cases where the simulated distribution does not provide support coverage of the \"ground truth\" observations.  I feel two ways about this: the KL divergence is the culprit here, and the problem could be avoided by choosing another divergence measure.  However the definintion of KL divergence in information theoretic terms of compression make it seem more foundational than other measures, but ultimately is this true?  Should we look to math statistics to make more direct links between f-divergences and what we use as a discriminant for a particular application?  Should we be more concerned about \"Bayesian consistency\" of the discriminant (or surrogate loss function) with the choice of divergence measure?\n",
    "\n",
    "\n",
    "1.  **Quantify the distribution of unsupported mass across all models**.  It is important to describe the extent of the problem across the sample **and** across various methods.  i.e. discrete distributions have the issue of support coverage, but so do all methods!\n",
    "2.  Even in kNN / ensemble simulation approaches, the problem of incomplete support coverage necessitates assuming some prior probability.  The issue is that setting a uniform prior over the observed range takes advantage of information about the observed range.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008336e7-cca2-440e-99da-e3919f351793",
   "metadata": {},
   "source": [
    "### Global Uniform Mixture\n",
    "\n",
    "$$f(x) = \\frac{1}{b-a}, \\quad x\\in (a, b) \\text{ and } f(x) = 0 \\text{ otherwise.}$$\n",
    "$$\\int_a^b f(x)\\text{dx} = 1$$\n",
    "\n",
    "Given the target range is a sub interval $(c, d) \\subseteq (a, b)$, then the **total** probability mass over (c, d) is:\n",
    "\n",
    "$$M_\\text{target} = \\int_c^d \\frac{1}{b-a}\\text{dx} = \\frac{d-c}{b-a}$$\n",
    "\n",
    "Over the set of intervals $\\Delta x_i$ covering the **target range**, the probability mass associated with each interval (bin) is given by: \n",
    "\n",
    "$$\\Delta x_i \\frac{d-c}{b-a}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2231b97e",
   "metadata": {},
   "source": [
    "### Compute the mean PDF across all stations\n",
    "\n",
    "Given a state space $\\Omega$ with $M$ discrete states, and $N$ spatially distributed sensors (streamflow monitoring stations) with PMFs $P=\\{p_j\\}_{j=1}^N$, we can define the mean PDF across all sensors in terms of the observed states $\\omega$ as follows:\n",
    "\n",
    "$$\\Omega=\\{\\omega_i\\}_{i=1}^M,\\quad P\\in\\mathbb{R}^{M\\times N},\\quad P_{i j}=p_j(\\omega_i),\\ \\sum_{i=1}^M P_{i j}=1.$$\n",
    "\n",
    "$$P_{i j}=\\Pr_j(B_i),\\qquad \\bar p_i =\\frac{1}{N}\\sum_{j=1}^N P_{i j}\\quad(\\text{mean PMF over sensors}).$$\n",
    "\n",
    "where $B_i$ denotes the $i$-th quantization bin (interval) in log-unit-area-runoff (L-UAR), i.e., $B_i = [y_i, y_{i+1})$ with $y_i = \\log(x_i)$. Each $P_{ij}$ is the probability assigned by sensor $j$ to bin $B_i$.\n",
    "\n",
    "$$\\text{Density per log-}x\\ (\\text{piecewise constant on }B_i):\\quad h_i=\\frac{\\bar p_i}{\\Delta y_i},\\qquad \\sum_i h_i\\,\\Delta y_i=1$$\n",
    "\n",
    "\n",
    "### Entropy of the mean PDF and fraction of $b$-bit quantization capacity\n",
    "\n",
    "$$M = 2^{b},\\qquad \\bar{\\mathbf p} = (\\bar p_1,\\ldots,\\bar p_M)^T,\\quad \\bar p_i \\ge 0,\\ \\sum_{i=1}^M \\bar p_i = 1$$\n",
    "\n",
    "$$\\text{Shannon entropy (bits):}\\quad H_2(\\bar{\\mathbf p}) \\;=\\; -\\sum_{i:\\,\\bar p_i>0} \\bar p_i \\log_2 \\bar p_i \\;\\le\\; b.\n",
    "$$\n",
    "\n",
    "$$\\text{Normalized entropy (fraction of capacity):}\\quad \\rho_b \\;=\\; \\frac{H_2(\\bar{\\mathbf p})}{b} \\in [0,1].$$\n",
    "\n",
    "$$\\text{Perplexity (effective bins):}\\quad \\mathcal P(\\bar{\\mathbf p}) \\;=\\; 2^{H_2(\\bar{\\mathbf p})},\\qquad\n",
    "\\text{occupancy fraction } \\phi_b \\;=\\; \\frac{\\mathcal P}{2^b} \\;=\\; 2^{H_2(\\bar{\\mathbf p})-b}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2c621f-81ff-4b85-a15f-f3b9565ebf90",
   "metadata": {},
   "source": [
    "## Notes on FDC estimation from distribution mixtures\n",
    "\n",
    "A desirable property of the estimated FDC is that it prevents predicting zero probabilities over the support $\\Omega$ while reflecting the strength of belief in the model (data).  To avoid predicting zero probabilities over the support, a component of the FDC estimation model is to add a uniform distribution component in the form of a mixture model: $\\hat Q = (1 - \\lambda) Q + \\lambda \\mathbb{U}$, where $U$ is the uniform distribution over the support.  The mixture ratio $\\lambda$ reflects the strength of belief in the model (data), where a smaller $\\lambda$ reflects stronger belief in the data/model and vice versa.  The strength of belief in the uniform component is a way of controlling how the addition of information by uniform noise influences the estimated distribution.  More importantly, the \"surprise\" of observing a state $p_i > 0$ where $q_i \\rightarrow 0$ grows to infinity, so care must be taken not just to prevent infinite divergence but also to consider what the addition of uniform noise in its place represents as far as a certainty in the frequency itself.  Simply assigning a very small number is not appropriate since it has a clear interpretation in terms of an expectation of how long it would take on average to observe the state. The mixture with a uniform component should not be so small as to represent a) a high degree of certainty in an event and b) an event that is far more rare than the observed duration without supporting (prior) information.\n",
    "\n",
    "\n",
    "1.  Incomplete support coverage, or underspecification, is infinitely penalized when the ground truth probability is nonzero..  The method does not tolerate a model that cannot predict the full observed range.\n",
    "2.  A **proper** probability distribution sums (discrete) or integrates (continuous) to 1.  Very small probabilities are in a sense associated with a high degree of certainty since they reflect the expectation of the system being observed in a particular state.\n",
    "3.  The penalty of underestimating a state frequency is that storing and transmitting information about the state requires (the log ratio) more bandwidth/disk space because it is assigned a longer bit string than the actual frequency calls for under optimal encoding.\n",
    "4.  Assigning a very small probability to a state ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71a48368-9dda-4442-a09c-c506db94ba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the predicted parameter results\n",
    "parameter_prediction_results_folder = os.path.join('data', 'results', 'parameter_prediction_results', )\n",
    "predicted_params_fpath   = os.path.join(parameter_prediction_results_folder, 'mean_parameter_predictions.csv')\n",
    "rdf = pd.read_csv(predicted_params_fpath, index_col=['official_id'], dtype={'official_id': str})\n",
    "predicted_param_dict = rdf.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "646ea56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"c14cb52c-8a96-419b-ab9d-6f3c79d02b56\" data-root-id=\"p1107\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"79cd3fec-7c35-497c-b931-46da39957d66\":{\"version\":\"3.8.0\",\"title\":\"Bokeh Application\",\"config\":{\"type\":\"object\",\"name\":\"DocumentConfig\",\"id\":\"p1109\",\"attributes\":{\"notifications\":{\"type\":\"object\",\"name\":\"Notifications\",\"id\":\"p1110\"}}},\"roots\":[{\"type\":\"object\",\"name\":\"GridPlot\",\"id\":\"p1107\",\"attributes\":{\"rows\":null,\"cols\":null,\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1106\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"ToolProxy\",\"id\":\"p1100\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1030\"},{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1076\"}]}},{\"type\":\"object\",\"name\":\"ToolProxy\",\"id\":\"p1101\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1031\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1077\",\"attributes\":{\"renderers\":\"auto\"}}]}},{\"type\":\"object\",\"name\":\"ToolProxy\",\"id\":\"p1102\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1032\",\"attributes\":{\"dimensions\":\"both\",\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1033\",\"attributes\":{\"syncable\":false,\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"handles\":{\"type\":\"object\",\"name\":\"BoxInteractionHandles\",\"id\":\"p1039\",\"attributes\":{\"all\":{\"type\":\"object\",\"name\":\"AreaVisuals\",\"id\":\"p1038\",\"attributes\":{\"fill_color\":\"white\",\"hover_fill_color\":\"lightgray\"}}}}}}}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1078\",\"attributes\":{\"dimensions\":\"both\",\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1079\",\"attributes\":{\"syncable\":false,\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"handles\":{\"type\":\"object\",\"name\":\"BoxInteractionHandles\",\"id\":\"p1085\",\"attributes\":{\"all\":{\"type\":\"object\",\"name\":\"AreaVisuals\",\"id\":\"p1084\",\"attributes\":{\"fill_color\":\"white\",\"hover_fill_color\":\"lightgray\"}}}}}}}}]}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1103\"},{\"type\":\"object\",\"name\":\"ToolProxy\",\"id\":\"p1104\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1041\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1087\"}]}},{\"type\":\"object\",\"name\":\"ToolProxy\",\"id\":\"p1105\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1042\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1088\"}]}}]}},\"children\":[[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1008\",\"attributes\":{\"width\":400,\"height\":400,\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1009\"},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1010\"},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1018\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1019\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1011\",\"attributes\":{\"text\":\"Predicted log_uar_mean_mean_predicted\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1049\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1043\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1044\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1045\"},\"data\":{\"type\":\"map\",\"entries\":[[\"top\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"H4sIAAEAAAAC/1P4GfdZprrdXgtMl9s/sGrfFjpnov0NML3QXhUsPt2eAQpuQOUh6pfb+3oHPl+sssE+S2tvK7vIZnsFqDi6fOx2M4MnkXvt2Zbn/J96cZ99CZRfBNZ32N5GKSL3wfnD9tY3Tk1syDplL3EhtTJS7TTUPRftF/VGb6hbetV+dUqS2e6Am1Dzr9uHL+v6+bnwsv3nDz9vfTW7Ye9aO7HeQPa6/RGoPoh95+wvzGN/ntd7Hs5PZDzC7bL/mL3d+ovie0XPQe2/DDfv0XGGRKNHp+1NoO7XgoaDFkp4tdsDADVgUZhAAQAA\"},\"shape\":[40],\"dtype\":\"float64\",\"order\":\"little\"}],[\"left\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"H4sIAAEAAAAC/wFAAb/+h8+MNKeh+L8itiaj6xb2v76cwBEwjPO/WoNagHQB8b/q0+jdce3svyGhHLv61+e/WG5QmIPC4r8cdwjrGFrbv4wRcKUqL9G/8K9ef/EQvL/AzAUujzWpP1g+slZAo8o/vITxcI581z8m9URbvtPgP/InEX416eU/ulrdoKz+6j/BxtThEQrwPyXgOnPNlPI/ifmgBIkf9T/vEgeWRKr3P1MsbScANfo/t0XTuLu//D8dXzlKd0r/P0C8z22Z6gBA8siCNvcvAkCk1TX/VHUDQFbi6MeyugRACO+bkBAABkC8+05ZbkUHQG4IAiLMighAIBW16inQCUDSIWizhxULQIQuG3zlWgxANjvOREOgDUDoR4ENoeUOQE0qGmt/FRBAprBzTy64EEAAN80z3VoRQFm9JhiM/RFAskOA/DqgEkDdyWtEQAEAAA==\"},\"shape\":[40],\"dtype\":\"float64\",\"order\":\"little\"}],[\"right\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"H4sIAAEAAAAC/wFAAb/+IrYmo+sW9r++nMARMIzzv1qDWoB0AfG/6tPo3XHt7L8hoRy7+tfnv1huUJiDwuK/HHcI6xha27+MEXClKi/Rv/CvXn/xELy/wMwFLo81qT9YPrJWQKPKP7yE8XCOfNc/JvVEW77T4D/yJxF+NenlP7pa3aCs/uo/wcbU4REK8D8l4DpzzZTyP4n5oASJH/U/7xIHlkSq9z9TLG0nADX6P7dF07i7v/w/HV85SndK/z9AvM9tmeoAQPLIgjb3LwJApNU1/1R1A0BW4ujHsroEQAjvm5AQAAZAvPtOWW5FB0BuCAIizIoIQCAVteop0AlA0iFos4cVC0CELht85VoMQDY7zkRDoA1A6EeBDaHlDkBNKhprfxUQQKawc08uuBBAADfNM91aEUBZvSYYjP0RQLJDgPw6oBJAC8rZ4OlCE0D+AuzhQAEAAA==\"},\"shape\":[40],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1050\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1051\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Quad\",\"id\":\"p1046\",\"attributes\":{\"left\":{\"type\":\"field\",\"field\":\"left\"},\"right\":{\"type\":\"field\",\"field\":\"right\"},\"bottom\":{\"type\":\"value\",\"value\":0},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"fill_color\":{\"type\":\"value\",\"value\":\"lightblue\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Quad\",\"id\":\"p1047\",\"attributes\":{\"left\":{\"type\":\"field\",\"field\":\"left\"},\"right\":{\"type\":\"field\",\"field\":\"right\"},\"bottom\":{\"type\":\"value\",\"value\":0},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"value\",\"value\":\"lightblue\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Quad\",\"id\":\"p1048\",\"attributes\":{\"left\":{\"type\":\"field\",\"field\":\"left\"},\"right\":{\"type\":\"field\",\"field\":\"right\"},\"bottom\":{\"type\":\"value\",\"value\":0},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"value\",\"value\":\"lightblue\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1017\",\"attributes\":{\"tools\":[{\"id\":\"p1030\"},{\"id\":\"p1031\"},{\"id\":\"p1032\"},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1040\"},{\"id\":\"p1041\"},{\"id\":\"p1042\"}]}},\"toolbar_location\":null,\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1025\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1026\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1027\"},\"axis_label\":\"$$P(x)$$\",\"axis_label_text_font\":\"Bitstream Charter\",\"axis_label_text_font_size\":\"14pt\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1028\"},\"major_label_text_font\":\"Bitstream Charter\",\"major_label_text_font_size\":\"12pt\"}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1020\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1021\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1022\"},\"axis_label\":\"$$\\\\text{Log Mean UAR }(L/s/\\\\text{km}^2)$$\",\"axis_label_text_font\":\"Bitstream Charter\",\"axis_label_text_font_size\":\"14pt\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1023\"},\"major_label_text_font\":\"Bitstream Charter\",\"major_label_text_font_size\":\"12pt\"}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1024\",\"attributes\":{\"axis\":{\"id\":\"p1020\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1029\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1025\"}}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p1052\",\"attributes\":{\"label_text_font\":\"Bitstream Charter\",\"label_text_font_size\":\"12pt\",\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1053\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"\"},\"renderers\":[{\"id\":\"p1049\"}]}}]}}]}},0,0],[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1054\",\"attributes\":{\"width\":400,\"height\":400,\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1055\"},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1056\"},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1064\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1065\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1057\",\"attributes\":{\"text\":\"Predicted log_uar_std_mean_predicted\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1095\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1089\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1090\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1091\"},\"data\":{\"type\":\"map\",\"entries\":[[\"top\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"H4sIAAEAAAAC//sQoRYt92yl/eZDMUem5Vy251XpVnukdNe+45tYxFnTR/aruuTWeu5+Yy/koLWpo/qHfdEesf8lE/7brwvQ4XolwejgcO2zh8DXf/ZcZcvaT1l8tl98YFZTd8Vz+77v339c0n9gf7z3YH/Uymv2X/qbL6bOvWT/G2zfSaj4Nvv+Tlsel4Pn7HeD7d9sfwcq/gTqLgY0IBgJEp8JlZ9pvxqsb7E9RLwTLg6hEXyYfpg4AwFASB1MHgAGmlqqQAEAAA==\"},\"shape\":[40],\"dtype\":\"float64\",\"order\":\"little\"}],[\"left\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"H4sIAAEAAAAC/wFAAb/+TL8rH9Wy4j83v7WhzwDlPyK/PyTKTuc/Db/JpsSc6T/4vlMpv+rrP+O+3au5OO4/Z98zF1pD8D9c33hYV2rxP1LfvZlUkfI/SN8C21G48z8930ccT9/0PzLfjF1MBvY/KN/Rnkkt9z8e3xbgRlT4PxPfWyFEe/k/CN+gYkGi+j/+3uWjPsn7P/TeKuU78Pw/6d5vJjkX/j/e3rRnNj7/P2rvfNSZMgBAZW8fdRjGAEBg78EVl1kBQFpvZLYV7QFAVe8GV5SAAkBQb6n3EhQDQErvS5iRpwNARW/uOBA7BEBA75DZjs4EQDtvM3oNYgVANe/VGoz1BUAwb3i7CokGQCvvGlyJHAdAJm+9/AewB0Ah71+dhkMIQBtvAj4F1whAFu+k3oNqCUARb0d/Av4JQAvv6R+BkQpABm+MwP8kC0BiG8RVQAEAAA==\"},\"shape\":[40],\"dtype\":\"float64\",\"order\":\"little\"}],[\"right\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"H4sIAAEAAAAC/wFAAb/+N7+1oc8A5T8ivz8kyk7nPw2/yabEnOk/+L5TKb/q6z/jvt2ruTjuP2ffMxdaQ/A/XN94WFdq8T9S372ZVJHyP0jfAttRuPM/Pd9HHE/f9D8y34xdTAb2Pyjf0Z5JLfc/Ht8W4EZU+D8T31shRHv5PwjfoGJBovo//t7loz7J+z/03irlO/D8P+nebyY5F/4/3t60ZzY+/z9q73zUmTIAQGVvH3UYxgBAYO/BFZdZAUBab2S2Fe0BQFXvBleUgAJAUG+p9xIUA0BK70uYkacDQEVv7jgQOwRAQO+Q2Y7OBEA7bzN6DWIFQDXv1RqM9QVAMG94uwqJBkAr7xpciRwHQCZvvfwHsAdAIe9fnYZDCEAbbwI+BdcIQBbvpN6DaglAEW9HfwL+CUAL7+kfgZEKQAZvjMD/JAtAAe8uYX64C0A6osz+QAEAAA==\"},\"shape\":[40],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1096\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1097\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Quad\",\"id\":\"p1092\",\"attributes\":{\"left\":{\"type\":\"field\",\"field\":\"left\"},\"right\":{\"type\":\"field\",\"field\":\"right\"},\"bottom\":{\"type\":\"value\",\"value\":0},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"fill_color\":{\"type\":\"value\",\"value\":\"lightblue\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Quad\",\"id\":\"p1093\",\"attributes\":{\"left\":{\"type\":\"field\",\"field\":\"left\"},\"right\":{\"type\":\"field\",\"field\":\"right\"},\"bottom\":{\"type\":\"value\",\"value\":0},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"value\",\"value\":\"lightblue\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Quad\",\"id\":\"p1094\",\"attributes\":{\"left\":{\"type\":\"field\",\"field\":\"left\"},\"right\":{\"type\":\"field\",\"field\":\"right\"},\"bottom\":{\"type\":\"value\",\"value\":0},\"top\":{\"type\":\"field\",\"field\":\"top\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"value\",\"value\":\"lightblue\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1063\",\"attributes\":{\"tools\":[{\"id\":\"p1076\"},{\"id\":\"p1077\"},{\"id\":\"p1078\"},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1086\"},{\"id\":\"p1087\"},{\"id\":\"p1088\"}]}},\"toolbar_location\":null,\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1071\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1072\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1073\"},\"axis_label\":\"$$P(x)$$\",\"axis_label_text_font\":\"Bitstream Charter\",\"axis_label_text_font_size\":\"14pt\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1074\"},\"major_label_text_font\":\"Bitstream Charter\",\"major_label_text_font_size\":\"12pt\"}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1066\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1067\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1068\"},\"axis_label\":\"$$\\\\text{Log SD UAR }(L/s/\\\\text{km}^2)$$\",\"axis_label_text_font\":\"Bitstream Charter\",\"axis_label_text_font_size\":\"14pt\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1069\"},\"major_label_text_font\":\"Bitstream Charter\",\"major_label_text_font_size\":\"12pt\"}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1070\",\"attributes\":{\"axis\":{\"id\":\"p1066\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1075\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1071\"}}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p1098\",\"attributes\":{\"label_text_font\":\"Bitstream Charter\",\"label_text_font_size\":\"12pt\",\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1099\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"\"},\"renderers\":[{\"id\":\"p1095\"}]}}]}}]}},0,1]]}}]}};\n  const render_items = [{\"docid\":\"79cd3fec-7c35-497c-b931-46da39957d66\",\"roots\":{\"p1107\":\"c14cb52c-8a96-419b-ab9d-6f3c79d02b56\"},\"root_ids\":[\"p1107\"]}];\n  void root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p1107"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots = []\n",
    "predicted_param_sample = {}\n",
    "for l, al in zip(['log_uar_mean_mean_predicted', 'log_uar_std_mean_predicted'], [r'$$\\text{Log Mean UAR }(L/s/\\text{km}^2)$$', r'$$\\text{Log SD UAR }(L/s/\\text{km}^2)$$']):\n",
    "    vals = [d[l] for _, d in predicted_param_dict.items()]\n",
    "    predicted_param_sample[l] = vals\n",
    "    # plot the histogram of the mean_uar values\n",
    "    hist, edges = np.histogram(vals, bins=40, density=True)\n",
    "    # create a scatter plot of the predicted parameter vs the target parameter\n",
    "    f = figure(title=f'Predicted {l}', width=600, height=400)\n",
    "    f.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], fill_color='lightblue', line_color='black', legend_label='')\n",
    "    f.xaxis.axis_label = al\n",
    "    f.yaxis.axis_label = r'$$P(x)$$'\n",
    "    f = dpf.format_fig_fonts(f, font_size=14)\n",
    "    plots.append(f)\n",
    "# retrieve all the mean_uar values \n",
    "\n",
    "lt = gridplot(plots, ncols=2, width=400, height=400)\n",
    "show(lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46b4bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FDCEstimatorRunner:\n",
    "    def __init__(self, stn_id, ctx, methods, k_nearest, parametric_target_cols, estimator_classes, **kwargs):\n",
    "        self.stn_id = stn_id\n",
    "        self.ctx = ctx\n",
    "        self.methods = methods\n",
    "        self.k_nearest = k_nearest\n",
    "        self.parametric_target_cols = parametric_target_cols\n",
    "        self.ESTIMATOR_CLASSES = estimator_classes\n",
    "        self._create_results_folders()\n",
    "        self._create_readme()\n",
    "        \n",
    "\n",
    "    def _create_results_folders(self):\n",
    "        # create a results foder for each method if it doesn't exist\n",
    "        self.results_folder = os.path.join('data', 'results', f'fdc_estimation_results',)\n",
    "        for method in self.methods:\n",
    "            method_folder = os.path.join(self.results_folder, method)\n",
    "            if method == 'lstm':\n",
    "                self.lstm_rev_date = self.ctx.LSTM_ensemble_result_folder.split('_')[-1]\n",
    "                method_folder = os.path.join(self.results_folder, f'{method}_{self.lstm_rev_date}')\n",
    "            if not os.path.exists(method_folder):\n",
    "                os.makedirs(method_folder)\n",
    "\n",
    "\n",
    "    def _create_readme(self):\n",
    "        # create a readme file in the results folder to list constraints\n",
    "        readme_file = os.path.join(self.results_folder, 'README.txt')\n",
    "        \n",
    "        with open(readme_file, 'w') as file:\n",
    "            file.write(\"This folder contains the results of the FDC estimation.\\n\")\n",
    "            file.write(f\"Methods evaluated: {', '.join(self.methods)}\\n\")\n",
    "            # add the concurrency constraint and number of stations represented in the network\n",
    "            N = len(self.ctx.official_ids)\n",
    "            if self.ctx.include_pre_1980_data == False:\n",
    "                file.write(f'Uses only stations within Daymet input period of record / LSTM results: N={N} stations in the network.\\n')\n",
    "                file.write(f'Global start date on streamflow data: {self.ctx.global_start_date}\\n')\n",
    "            else:\n",
    "                file.write(f'Uses all available network stations in the BCUB region (1950-2024): N={N} stationsin the network.')\n",
    "                \n",
    "\n",
    "    def _load_reference_distributions(self):\n",
    "        self.log_edges = self.data.log_edges\n",
    "        self.log_w = self.data.log_w\n",
    "        self.log_x = self.data.log_x\n",
    "        self.lin_x = self.data.lin_x\n",
    "        self.kde = KDEEstimator(self.log_edges)\n",
    "        # self.baseline_obs_pmf, self.baseline_obs_pdf = self.data.baseline_pmf, self.data.baseline_pdf\n",
    "\n",
    "\n",
    "    def _save_result(self, result):\n",
    "        with open(self.result_file, 'w') as file:\n",
    "            json.dump(result, file, indent=4)\n",
    "\n",
    " \n",
    "    def run_selected(self):\n",
    "        # check the minimum number of years of overlap for all stations in self.ctx.overlap_dict\n",
    "        for method in self.methods:\n",
    "            self.result_file = os.path.join(self.results_folder, method, f'{self.stn_id}_fdc_results.json')\n",
    "            if method == 'lstm':\n",
    "                method_folder = f'{method}_{self.lstm_rev_date}'\n",
    "                self.result_file = os.path.join(self.results_folder, method_folder, f'{self.stn_id}_fdc_results.json')\n",
    "            \n",
    "            if os.path.exists(self.result_file):\n",
    "                continue\n",
    "            else:\n",
    "                self.data = StationData(self.ctx, self.stn_id)\n",
    "                self.data.k_nearest = self.k_nearest\n",
    "                self.data.parametric_target_cols = self.parametric_target_cols\n",
    "                self._load_reference_distributions()\n",
    "\n",
    "                self.data.kde_estimator = KDEEstimator(self.data.log_edges)\n",
    "                self.data.eval_metrics = EvaluationMetrics(self.data)\n",
    "\n",
    "                EstimatorClass = self.ESTIMATOR_CLASSES[method]\n",
    "\n",
    "                estimator = EstimatorClass(\n",
    "                    self.ctx, self.data\n",
    "                )\n",
    "                result = estimator.run_estimators()\n",
    "                self._save_result(result)\n",
    "            # except Exception as e:\n",
    "            #     raise Exception(f\"  {method} estimator failed for {self.stn_id}: {str(e)}\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0ecf64f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "target_cols = [\n",
    "    'mean_uar', 'sd_uar', \n",
    "    'mean_logx', 'sd_logx', \n",
    "]\n",
    "\n",
    "attr_df_fpath = os.path.join('data', f'catchment_attributes_with_runoff_stats.csv')\n",
    "LSTM_forcings_folder = '/home/danbot/neuralhydrology/data/BCUB_catchment_mean_met_forcings_20250320'\n",
    "baseline_distribution_folder = os.path.join('data', 'results', 'baseline_distributions')\n",
    "# parameter_prediction_results_folder = os.path.join('data', 'parameter_prediction_results')\n",
    "\n",
    "methods = ('parametric', 'lstm', 'knn',)\n",
    "# methods = ('knn',)\n",
    "k_nearest = 10\n",
    "include_pre_1980_data = True  # use only stations with data 1980-present concurrent with Daymet\n",
    "daymet_start_date = '1980-01-01'  # default start date for Daymet data\n",
    "if include_pre_1980_data:\n",
    "    daymet_start_date = '1950-01-01'\n",
    "\n",
    "processed = []\n",
    "ESTIMATOR_CLASSES = {\n",
    "    'parametric': ParametricFDCEstimator,\n",
    "    'lstm': LSTMFDCEstimator,\n",
    "    'knn': kNNEstimator,\n",
    "    # add others here\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c667fad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Using all stations in the catchment data with a baseline PMF (validated): 1020\n",
      "    ...overlap dict loaded from data/record_overlap_dict.json\n"
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    'attr_df_fpath': attr_df_fpath,\n",
    "    'LSTM_forcings_folder': LSTM_forcings_folder,\n",
    "    'LSTM_ensemble_result_folder': LSTM_ensemble_result_folder,\n",
    "    'include_pre_1980_data': include_pre_1980_data,  # use only stations with data 1980-present concurrent with Daymet\n",
    "    'predicted_param_dict': predicted_param_dict,\n",
    "    'divergence_measures': ['DKL', 'EMD'],\n",
    "    'eps': 1e-12,\n",
    "    'min_flow': 1e-4,\n",
    "    'n_grid_points': 2**12,\n",
    "    'min_record_length': 5,\n",
    "    'minimum_days_per_month': 20,\n",
    "    'parametric_target_cols': target_cols,\n",
    "    'all_station_ids': official_ids_to_include,\n",
    "    'daymet_concurrent_stations': daymet_concurrent_stations,\n",
    "    'baseline_distribution_folder': baseline_distribution_folder,\n",
    "    # 'prior_strength': 1e-2,  # prior strength for the Laplace fit\n",
    "    'delta': 0.01 # maximum perturbation of the predicted PMF by the uniform mixture ratio\n",
    "}\n",
    "\n",
    "context = FDCEstimationContext(**input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d6acab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FDCs...\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 10.02s for temporal ensemble, 0.97s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 3.91s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 9.62s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 4.63s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.44s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.06s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.48s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.44s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 9.85s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.74s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 7.12s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.00s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 9.33s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.54s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 8.97s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.64s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.34s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.80s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.01s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.30s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 7.89s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.14s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 5.61s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.08s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.43s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.78s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.43s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 4.24s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 10.54s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.10s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 6.60s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 3.97s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 7.73s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.59s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 7.51s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.95s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.02s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.81s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 8.58s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 2.77s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "Processed 10/1016 stations in 40.89 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 6.25s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.92s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 4.53s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 4.60s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.78s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.92s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 9.88s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.65s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.82s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.81s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.23s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.93s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 5.06s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 2.76s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 6.42s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.28s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 9.05s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.59s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 5.85s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.11s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.81s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.68s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.73s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.51s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.81s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 3.14s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.85s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.76s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 8.54s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.28s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 7.32s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.13s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 9.32s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.00s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 7.02s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.31s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.66s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.12s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 9.39s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.72s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "Processed 20/1016 stations in 41.16 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 10.95s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.05s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.46s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.25s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 9.08s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.38s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 7.44s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 4.89s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 7.34s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.37s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 7.98s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 4.83s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.16s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.83s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.43s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.75s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.12s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.00s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.44s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 4.64s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 10.89s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.19s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.21s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.85s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 10.59s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.88s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.04s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.19s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.01s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.84s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.02s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.91s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.83s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.56s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 8.78s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.99s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.56s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.68s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 8.08s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.27s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "Processed 30/1016 stations in 42.59 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.81s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.35s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.95s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.27s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 9.88s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 3.77s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.10s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 4.31s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.11s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.79s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.12s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.10s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.03s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.83s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.55s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 4.58s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.98s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 2.65s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 17.08s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.49s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.15s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.98s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.21s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.57s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.31s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.48s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.87s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.54s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 9.98s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 1.50s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.14s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.30s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.15s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.23s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.32s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 4.52s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 16.66s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.46s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 8.87s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.26s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "Processed 40/1016 stations in 43.96 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 9.17s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.68s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 14.40s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.14s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.88s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.83s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 8.61s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.63s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 10.90s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.05s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.56s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.44s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.27s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.11s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.96s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 10.48s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.60s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.95s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.67s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 3.99s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.56s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.11s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.45s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.62s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.73s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.93s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.58s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.05s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.37s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.82s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.00s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.42s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.14s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.69s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.29s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.64s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.04s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.62s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.09s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.12s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "Processed 50/1016 stations in 44.74 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.62s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.52s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 8.19s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.51s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.26s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 3.27s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 16.37s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 3.91s for temporal ensemble, 0.26s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.55s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 3.70s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.53s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.71s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 16.23s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.71s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.05s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.90s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.85s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.38s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 16.39s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.83s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.39s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.54s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.39s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.57s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 10.51s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.17s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.24s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.74s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 10.85s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.89s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.35s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.54s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.22s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.47s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 7.24s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.58s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.43s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.97s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.68s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.16s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "Processed 60/1016 stations in 45.55 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.51s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.53s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.83s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.14s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.37s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 9.04s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 17.13s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 4.89s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.89s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.42s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.58s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.04s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.70s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.69s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.96s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.74s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.46s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.01s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.03s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.16s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.29s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.97s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 15.48s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.09s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 10.69s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.69s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 14.67s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.18s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.62s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 10.93s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 14.87s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.51s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.23s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.78s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 15.38s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 2.85s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.57s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.17s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 16.56s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.24s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "Processed 70/1016 stations in 46.65 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.36s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.73s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 16.29s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.04s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.12s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.36s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.79s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.19s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 17.35s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.95s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 16.55s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 4.89s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.91s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.49s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 15.57s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.10s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.49s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 10.84s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.50s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.16s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.26s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.87s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.89s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.80s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.18s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.27s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.09s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.71s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.98s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.22s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 14.76s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.12s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.92s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.27s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.92s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.14s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.01s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.85s for temporal ensemble, 0.31s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 16.11s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.15s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "Processed 80/1016 stations in 47.49 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.78s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.02s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 15.82s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.22s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.11s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.02s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 14.67s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.05s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.82s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.73s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.29s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.87s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 17.59s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.95s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.28s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.59s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.32s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.48s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 14.03s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.23s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 17.55s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.26s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.98s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.32s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 9.17s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.71s for temporal ensemble, 0.31s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 7.18s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.18s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.92s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.42s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.42s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.14s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.11s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.45s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 14.07s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.02s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.25s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.66s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 15.27s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.00s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "Processed 90/1016 stations in 47.96 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.97s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.47s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 15.68s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.80s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 19.39s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.25s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.52s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.75s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.17s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.16s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.52s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.66s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.50s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.27s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.23s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 3.97s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 9.41s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.89s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 17.67s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.81s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.51s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.63s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.46s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.75s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.35s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.71s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 14.68s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.30s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.90s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.15s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 9.65s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 4.56s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.16s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.62s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 17.13s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.69s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.37s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.08s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.52s for temporal ensemble, 0.31s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.32s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "Processed 100/1016 stations in 48.46 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.21s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.79s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.56s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 13.96s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 16.36s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.91s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 15.34s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.13s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 17.19s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.76s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 14.13s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.53s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.55s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.20s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.43s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.52s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.92s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.09s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 14.09s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.58s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.20s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 9.42s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 9.38s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.17s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.46s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 3.72s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.26s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.86s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 18.02s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.20s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 14.15s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.45s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 16.06s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.63s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.98s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 9.25s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.32s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.73s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.43s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.27s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "Processed 110/1016 stations in 49.04 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.39s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.23s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 16.20s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.37s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.61s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.44s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.61s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.02s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 10.35s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.85s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 15.31s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.50s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 16.11s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.61s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.34s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.37s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 9.35s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 9.31s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 7.79s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.66s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.42s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.37s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 9.04s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.20s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.17s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 3.22s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 18.30s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.34s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.36s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.33s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 7.77s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.16s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.19s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.52s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 9.89s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 9.19s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.06s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.55s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.44s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.17s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "Processed 120/1016 stations in 49.31 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.67s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.59s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 15.30s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.28s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.77s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.53s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.45s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.02s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.88s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.83s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.66s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 15.69s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.86s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.29s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.64s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.61s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 16.41s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.36s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.84s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.52s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.58s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.57s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.39s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.62s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 17.01s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.33s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.67s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.66s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.52s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.31s for temporal ensemble, 0.31s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 15.18s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 4.53s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 10.71s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.15s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 8.76s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.40s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.51s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.15s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.63s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.80s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "Processed 130/1016 stations in 49.49 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 9.34s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.41s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 14.46s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.62s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.58s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.00s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.04s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.50s for temporal ensemble, 0.33s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 17.36s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.19s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.44s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.13s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.74s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.28s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 6.45s for temporal ensemble, 0.31s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 4.98s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.28s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.31s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.56s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.68s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.79s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.22s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 17.11s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 12.68s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.48s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.88s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 9.51s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.92s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 10.77s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.26s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 15.67s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.50s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.55s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.46s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.67s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.24s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.35s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.52s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 9.73s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.91s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "Processed 140/1016 stations in 49.73 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.43s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 3.00s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 15.40s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.78s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.47s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.05s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 9.27s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.71s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.19s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.60s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 9.03s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.84s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.49s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 9.32s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 7.76s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.42s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 7.96s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.97s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 16.32s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.65s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 17.51s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.56s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.37s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.31s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 16.42s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.16s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 14.59s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.24s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 19.21s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.77s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 16.18s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.16s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 16.23s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.36s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.22s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.25s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.23s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.70s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 20.49s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.68s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "Processed 150/1016 stations in 50.02 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.77s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.33s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 9.87s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.11s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 16.61s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 9.35s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 17.43s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.53s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.64s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.40s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.67s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 9.13s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.63s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.67s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 15.07s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.42s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.41s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.13s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 14.67s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.06s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.61s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.43s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.24s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.53s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.10s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.69s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.49s for temporal ensemble, 0.31s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 9.33s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.61s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.29s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 6.15s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.47s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.61s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.56s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.93s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.93s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 16.45s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.60s for temporal ensemble, 0.31s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 15.22s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.33s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "Processed 160/1016 stations in 50.30 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.21s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.79s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 9.00s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.80s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.14s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.16s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.53s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.15s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.60s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.31s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.40s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.21s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.70s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 9.59s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 7.93s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 9.92s for temporal ensemble, 8.46s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.04s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.37s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 18.56s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.42s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.30s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.97s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 16.64s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 9.78s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.43s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.58s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.71s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.04s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.94s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.59s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.57s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.55s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.67s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.94s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 16.54s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.64s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.09s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.72s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.88s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.17s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "Processed 170/1016 stations in 50.63 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 16.65s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 9.66s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.67s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.26s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.63s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 3.95s for temporal ensemble, 0.27s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.38s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.85s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 10.59s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.90s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.46s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.81s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.85s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.61s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.49s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.39s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.02s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.12s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.43s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.53s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.54s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.88s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.40s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 4.79s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.75s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.32s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.69s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 3.71s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.47s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 3.30s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.60s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.41s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 10.07s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.92s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 17.33s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 3.71s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 16.40s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.80s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 14.72s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 16.18s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "Processed 180/1016 stations in 50.80 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 16.51s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.25s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.38s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.32s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.19s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.59s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.54s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.39s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.57s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.49s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.42s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.51s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.74s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.99s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.72s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.20s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.62s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.67s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.30s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 6.64s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.67s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.07s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.70s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.26s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.45s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.68s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 18.60s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.77s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 12.47s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.42s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 10.07s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.06s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.84s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.95s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 9.53s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 9.77s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.86s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.40s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 13.70s for temporal ensemble, 0.31s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.77s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "Processed 190/1016 stations in 50.78 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.28s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.91s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 16.56s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 4.33s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 16.51s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.72s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 15.97s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.06s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.68s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.15s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 16.28s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.67s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.54s for temporal ensemble, 0.28s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.87s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 9.48s for temporal ensemble, 0.31s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.16s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 11.06s for temporal ensemble, 0.31s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.16s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 7.41s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.96s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.29s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 4.70s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 11.71s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.50s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 16.23s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 6.84s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 8.13s for temporal ensemble, 0.31s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 5.60s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 14.34s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 5.53s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 12.30s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.39s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 26.80s for temporal ensemble, 0.32s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 8.62s for temporal ensemble, 0.31s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 15.36s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.64s for temporal ensemble, 0.31s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.06s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.90s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 14.71s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 8.81s for temporal ensemble, 0.30s for frequency ensemble.\n",
      "Processed 200/1016 stations in 50.97 seconds per station\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 15.14s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...spatial_dist ID2 took 7.20s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID1 took 18.24s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...attribute_dist ID2 took 7.28s for temporal ensemble, 0.29s for frequency ensemble.\n",
      "    ...initializing nearest neighbours with minimum concurrent record.\n",
      "    ...spatial_dist ID1 took 13.28s for temporal ensemble, 0.30s for frequency ensemble.\n"
     ]
    }
   ],
   "source": [
    "processed = []\n",
    "t0 = time()\n",
    "process_fdcs = True\n",
    "if process_fdcs:\n",
    "    print('Processing FDCs...')\n",
    "    for stn in daymet_concurrent_stations:\n",
    "        # if stn in missing_lstm_set2: # this station has no data in the LSTM ensemble results\n",
    "        #     print(f'    ...skipping {stn} due to naming issue.')\n",
    "        #     continue\n",
    "        # actual_mean = predicted_param_dict[stn]['uar_mean_actual']\n",
    "        # print(f'  Estimating FDC for  {stn}.  Actual mean UAR={foo:.2f} L/s/km2')\n",
    "        runner = FDCEstimatorRunner(stn, context, methods, k_nearest, target_cols, ESTIMATOR_CLASSES)\n",
    "        runner.run_selected()\n",
    "        processed.append(stn)\n",
    "        if len(processed) % 10 == 0:\n",
    "            t1 = time()\n",
    "            elapsed = t1 - t0\n",
    "            unit_time = elapsed / len(processed)\n",
    "            print(f'Processed {len(processed)}/{len(context.official_ids)} stations in {unit_time:.2f} seconds per station')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992e3392",
   "metadata": {},
   "source": [
    "## Example case of bad KDE fit due to sparse support and precision vestiges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795f798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pdf_fig(y1, test_data, ts):\n",
    "\n",
    "    # check y1 (pdf) integrates to 1 over baseline_log_grid\n",
    "    y1_integral = np.trapezoid(y1, x=test_data.log_x)\n",
    "\n",
    "    # set up a histogram of the observed data\n",
    "    xx = np.linspace(np.min(np.log(ts)), np.max(np.log(ts)), 50)\n",
    "    hist, edges = np.histogram(np.log(ts), bins=xx, density=True)\n",
    "    # compute the maximum bin probability mass\n",
    "    dx = edges[1] - edges[0]\n",
    "    max_bin_prob = hist.max() * dx  # bin width\n",
    "    foo = hist * dx\n",
    "    print(f'Max bin probability mass: {max_bin_prob:.4f}, y1 integral: {y1_integral:.4f}')\n",
    "\n",
    "    # plot the adaptive PMF and the FFTKDE result\n",
    "    edges = np.exp(edges)\n",
    "    # f = figure(title=f'{target_id}', width=600, height=400, x_axis_type='log')\n",
    "    f = figure(title=f'', width=600, height=400, x_axis_type='log')\n",
    "    f.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], \n",
    "        fill_color='lightblue', line_color='dodgerblue', \n",
    "        legend_label='Observed Histogram')\n",
    "    # x_lin = np.exp(test_data.baseline_log_gr)\n",
    "    f.line(test_data.baseline_lin_grid, adaptive_pdf, line_width=2, color='green', legend_label='Adaptive BW')\n",
    "    f.line(test_data.baseline_lin_grid, y1, line_width=3, color='black', line_dash='dashed', legend_label='FFT KDE')\n",
    "    f.xaxis.axis_label = 'UAR (L/s/km2)'\n",
    "    f.yaxis.axis_label = 'Density'\n",
    "    f.legend.location = 'top_left'\n",
    "    f.legend.background_fill_alpha = 0.25\n",
    "    f.legend.click_policy = 'hide'\n",
    "    f = dpf.format_fig_fonts(f, font_size=14)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f94f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from KDEpy import FFTKDE\n",
    "bad_klds = ['05AB022', '12345000', '12353820', '08NL037', '08NA056', '08NA052', '12111500',\n",
    "            '08NA053', '08NH100', '12367500']\n",
    "bad_rmses = ['15031000', '12345000', '12067500', '08HB045', '15058700', '12353820',\n",
    "           '15052000', '15195000', '15067900', '08HA069']\n",
    "bad_nses = ['12353820', '12345000', '12091060', '12067500', '12111500', '08HB045',\n",
    "            '08HB047', '15031000', '10CD004', '12301550']\n",
    "\n",
    "# plots = []\n",
    "# for target_id in bad_nses:\n",
    "#     target_da= stn_da_dict[target_id]\n",
    "#     test_data = StationData(context, target_id)\n",
    "#     ts = test_data.stn_df[f'{target_id}_uar'].dropna().values\n",
    "#\n",
    "#     # get the unique UAR values\n",
    "#     unique_vals = sorted(np.unique(ts))\n",
    "#\n",
    "#     df =  test_data.stn_df.copy()\n",
    "#     df = df[df['zero_flow_flag'] == True].copy()\n",
    "#\n",
    "#     kde_obj = KDEEstimator(test_data.baseline_log_grid, test_data.log_dx)\n",
    "#     adaptive_pmf, adaptive_pdf = kde_obj.compute(ts, target_da)\n",
    "#\n",
    "#     y1 = FFTKDE(bw=\"silverman\").fit(np.log(ts)).evaluate(test_data.baseline_log_grid)\n",
    "#     f = generate_pdf_fig(y1, test_data, ts)\n",
    "#     plots.append(f)\n",
    "#\n",
    "# lt = gridplot(plots, ncols=2, width=550, height=400)\n",
    "# show(lt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c615cbf6",
   "metadata": {},
   "source": [
    "### Compute the complexity of searching the space of k-nearest neighbours for the optimal ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711879b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import comb\n",
    "# from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.models import ColorBar, BasicTicker, HoverTool, ColumnDataSource\n",
    "from bokeh.transform import linear_cmap\n",
    "from bokeh.palettes import Viridis256\n",
    "\n",
    "def plot_search_space_heatmap(N_min=10, N_max=1000, N_step=10, k_max=10):# output_path=\"search_space_heatmap.html\"):\n",
    "    \"\"\"\n",
    "    Generate and save a Bokeh heatmap of log10(search space size) for ensembles of size 1 to k_max\n",
    "    from a network of size N, excluding the target node.\n",
    "\n",
    "    Parameters:\n",
    "    - N_min (int): Minimum network size.\n",
    "    - N_max (int): Maximum network size.\n",
    "    - N_step (int): Step between network sizes.\n",
    "    - k_max (int): Maximum ensemble size to consider.\n",
    "    - output_path (str): Path to save the HTML output.\n",
    "    \"\"\"\n",
    "    N_values = np.arange(N_min, N_max + 1, N_step)\n",
    "    k_values = np.arange(1, k_max + 1)\n",
    "\n",
    "    data = []\n",
    "    for N in N_values:\n",
    "        for k in k_values:\n",
    "            max_j = min(k, N - 1)\n",
    "            size = sum(comb(N - 1, j) for j in range(1, max_j + 1))\n",
    "            data.append((N, k, size))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['N', 'k', 'search_space'])\n",
    "    df['log_search_space'] = np.log10(df['search_space'].astype(float).replace(0, np.nan))\n",
    "\n",
    "    source = ColumnDataSource(df)\n",
    "\n",
    "    mapper = linear_cmap(field_name='log_search_space', palette=Viridis256,\n",
    "                         low=df['log_search_space'].min(), high=df['log_search_space'].max())\n",
    "\n",
    "    hover = HoverTool(\n",
    "        tooltips=[\n",
    "            (\"N\", \"@N\"),\n",
    "            (\"k\", \"@k\"),\n",
    "            (\"Search space\", \"@search_space{0,0}\"),\n",
    "            (\"log10(Search space)\", \"@log_search_space{0.00}\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    p = figure(title=\"Log10 of Search Space Size vs N and k\",\n",
    "               x_axis_label='Network size N',\n",
    "               y_axis_label='Ensemble size k',\n",
    "               x_range=(N_min, N_max), y_range=(1, k_max),\n",
    "               width=900, height=550,\n",
    "               tools=['pan', 'wheel_zoom', 'box_zoom', 'reset', hover])\n",
    "\n",
    "    p.rect(x=\"N\", y=\"k\", width=N_step, height=1, source=source,\n",
    "           line_color=None, fill_color=mapper)\n",
    "\n",
    "    color_bar = ColorBar(color_mapper=mapper['transform'], ticker=BasicTicker(),\n",
    "                         label_standoff=12, location=(0, 0), title='log10(search space)')\n",
    "    p.add_layout(color_bar, 'right')\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d001877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_search_space_heatmap()\n",
    "# show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f369708-c149-47fc-b0a3-060c1deff995",
   "metadata": {},
   "source": [
    "## Check sensitivity of variance estimation to the selection of quantiles\n",
    "\n",
    "The Nash-Sutcliffe Efficiency is the RMSE ($\\frac{1}{N}\\sum(y-\\hat y)^2)$) normalized by the observed variance $\\sigma^2 = \\sum(y-\\mu_y)^2$. When the NSE is computed on timeseries observations, the variance at least represents the sample.  When the NSE is used to describe the accuracy of an FDC described on a subjective set of quantiles, i.e. $\\{1, 2, \\dots, 99\\}$, the mean is an approximation that assumes the data are normally distributed.  This is not often the case, so here we examine the sensitivity of this metric to the choice of percentiles.  \n",
    "\n",
    "In short, the NSE ($1 - \\frac{RMSE}{\\sigma^2}$), which is already sensitive to outliers, will be overestimated if $\\sigma^2$ is overestimated, and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6262d54e-8589-45f2-a0e8-f4690e0e05f0",
   "metadata": {},
   "source": [
    "### Evaluate how biased a quantile-based spread estimate is at different resolutions\n",
    "\n",
    "Generate a dummy set of percentiles based on a wide range of number of points used to represent the FDC, and vary the inclusion of extremes.  In other words, vary the start end end points of the percentiles used to represent the FDC.  Including 0 and 100 in the set introduces the most structural uncertainty, and as we (symmetrically) exclude probability from the ends of the distribution, our estimate becomes less susceptible to extreme outlier errors based on the quadratic loss.  Likewise, having too many points (high number of quantiles near 0 and 100) has the same problem if some of the \"edge probability\" is not trimmed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcac79c",
   "metadata": {},
   "source": [
    "### Conventional Representation of FDCs\n",
    "\n",
    "In the literature, FDC estimation accuracy is computed in several different ways. One important difference among previous studies is the set of quantiles $\\{ p_j \\}$ over which residuals of the estimated and observed exceedance duration are evaluated.  The residuals are denoted $e_j = \\hat q(p_j) - q(p_j)$, where $\\hat q(p_j) = F^{-1}(p_j)$ are the estimated quantiles at exceedance percentiles $p_j$ and $q(p_j)$ are the observed quantiles.  The choice of probabilities reflects different research objectives in representing flow availability.\n",
    "\n",
    "* [0, 1, ..., 99, 100] {cite}`booker2014comparing`\n",
    "* [10, 20, ..., 80, 90] {cite}`li2010new`\n",
    "* [50, 51, ..., 99] {cite}`fennessey1990regional`\n",
    "\n",
    "The choice of exceedance durations to evaluate FDC estimates is determined on the basis of the precision and range of representation being appropriate for some application or question.  However the interpretation of the performance metric also depends upon this choice, in particular the statistical structure of the values being estimated.  A common metric between studies is the Nash Sutcliffe Efficiency (NSE) which divides the RMSE by the standard deviation.  Normalizing by the standard deviation implicitly assumes the residuals are normally distributed.  Alternatively, by the sample size (N) represents simply the mean, treating all residuals equally regardless of their distribution, except if the residuals are squared, then it emphasizes large values.  {cite}`booker2012comparing` and {cite}`booker2014comparing` (and others...) standardize the observed variable (unit area runoff) by dividing by the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f171330-5dc8-4865-8fd6-34110d8fe8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile_spread_convergence(obs, percentiles_list=None):\n",
    "    \"\"\"\n",
    "    Compare the standard deviation of observed data to that estimated from percentiles.\n",
    "\n",
    "    Parameters:\n",
    "    - obs: 1D array-like of observed values\n",
    "    - percentiles_list: list of lists/arrays of percentiles to compute (0–100).\n",
    "      If None, defaults to increasingly fine resolutions.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame with columns:\n",
    "        'num_percentiles', 'percentiles', 'spread_std', 'sample_std', 'relative_error'\n",
    "    \"\"\"\n",
    "    obs = np.asarray(obs)\n",
    "    sample_std = np.std(obs, ddof=0)\n",
    "    sample_mean = np.mean(obs)\n",
    "\n",
    "    if percentiles_list is None:\n",
    "        percentiles_list = [np.arange(10, 100, 10),\n",
    "                            np.arange(5, 100, 5),\n",
    "                            np.arange(2, 100, 2),\n",
    "                            np.arange(1, 100, 1),\n",
    "                           np.arange(0.1, 99.9, 0.1),\n",
    "                           np.arange(0.01, 99.99, 0.01), \n",
    "                           np.linspace(0, 100, 1000)]\n",
    "\n",
    "    results = []\n",
    "    for pct_set in percentiles_list:\n",
    "        q_vals = np.percentile(obs, pct_set)\n",
    "        spread_std = np.std(q_vals)\n",
    "        spread_mean = np.mean(q_vals)\n",
    "        rel_error = (spread_std - sample_std) / sample_std\n",
    "        mean_rel_error = (spread_mean - sample_mean) / sample_mean\n",
    "        results.append({\n",
    "            'num_percentiles': len(pct_set),\n",
    "            'percentiles': pct_set,\n",
    "            'spread_std': spread_std,\n",
    "            'sample_std': sample_std,\n",
    "            'relative_error': rel_error,\n",
    "            'mean_relative_error': mean_rel_error\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3313fcd-3ed8-4791-b395-e4cc8b808b8f",
   "metadata": {},
   "source": [
    "Note that this test represents a single site.  We are testing the \"precision of fdc representation\" and the \"sensitivity to extremes\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb4ec9f-e9e0-442a-91a4-a52f60267021",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_id = '08MH147'\n",
    "target_da= stn_da_dict[target_id]\n",
    "test_data = StationData(context, target_id)\n",
    "\n",
    "# get the unique UAR values\n",
    "df =  test_data.stn_df.copy()\n",
    "vals = df[f'{target_id}_uar'].dropna().values\n",
    "sdf = percentile_spread_convergence(vals)\n",
    "years = list(set(df.index.year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6795ee00-e9f3-4829-8eb7-48e98e4c045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import ColorBar, LinearColorMapper, BasicTicker, LogColorMapper\n",
    "from bokeh.transform import transform\n",
    "from bokeh.palettes import RdBu11, RdBu10\n",
    "from bokeh.models import ColumnDataSource, PrintfTickFormatter, CustomJSTickFormatter\n",
    "\n",
    "deltas = [0, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1, 2, 5, 10]\n",
    "P = [10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "P = [10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "\n",
    "def compute_sample_relative_error(vals, which_variable='std', log_transform=False):\n",
    "    # Convert axis values to strings for categorical plotting\n",
    "    deltas_str = [str(d) for d in deltas]\n",
    "    P_str = [str(p) for p in P]\n",
    "\n",
    "    log_vals = np.log(vals)\n",
    "    x = log_vals if log_transform else vals\n",
    "\n",
    "\n",
    "    # Prepare a matrix to store relative error\n",
    "    heatmap_data = np.zeros((len(deltas), len(P)))\n",
    "    # Fill the matrix\n",
    "    for i, d in enumerate(deltas):\n",
    "        for j, p in enumerate(P):\n",
    "            lower = d\n",
    "            upper = 100 - d\n",
    "            percentiles = np.linspace(lower, upper, p)\n",
    "            q_vals = np.percentile(x, percentiles)\n",
    "            if which_variable == 'std':\n",
    "                var = np.std(q_vals)\n",
    "                baseline = np.std(x)\n",
    "            elif which_variable == 'mean':\n",
    "                var = np.mean(q_vals)\n",
    "                baseline = np.mean(x)\n",
    "            else:\n",
    "                raise Exception(f'Unknown variable {which_variable}')\n",
    "\n",
    "            heatmap_data[i, j] = 100 * (var - baseline) / baseline\n",
    "\n",
    "    # Prepare dataframe for Bokeh\n",
    "    df = pd.DataFrame(heatmap_data, index=deltas_str, columns=P_str)\n",
    "    df.index.name = 'delta'\n",
    "    df.columns.name = 'P'\n",
    "    df = df.stack().rename(\"error\").reset_index()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee970471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rel_error(df, which_variable='std', log_transform=False):\n",
    "    if log_transform:\n",
    "        df['log_error'] = np.log(df['error'].abs())\n",
    "    else:\n",
    "        df['log_error'] = df['error']\n",
    "\n",
    "    source = ColumnDataSource(df)\n",
    "    min_err, max_err = df.log_error.min(), df.log_error.max()\n",
    "    print(f'{which_variable} {min_err:.4f}, {max_err:.4f}')\n",
    "\n",
    "    # Set up color mapper\n",
    "    mapper = LinearColorMapper(palette=RdBu11,\n",
    "                            low=min_err,\n",
    "                            high=max_err)\n",
    "    \n",
    "    title = \"Error of Quantile-based Std Dev vs Sample Std Dev [%]\"\n",
    "    cbar_label = 'Relative (Absolute) Error in Quantile-based Stdev. [%]'\n",
    "    err_label = '@error{0.0}%'\n",
    "    if which_variable == 'mean':\n",
    "        title = \"Relative Error of Quantile-based Mean vs Sample Mean\"\n",
    "        cbar_label = 'Relative Error in Quantile-based Mean [%]'\n",
    "        # err_label = \"@error{0.0} [L/s/km^2]\"\n",
    "    # Create figure\n",
    "    p = figure(x_range=[str(e) for e in P],\n",
    "            y_range=list(reversed([str(e) for e in deltas])),\n",
    "            x_axis_label=\"Size of Exceedance Percentile Set\",\n",
    "            y_axis_label=\"Symmetric Exclusion from [0, 100] (%)\",\n",
    "            title=title,\n",
    "            width=900,\n",
    "            height=400,\n",
    "            tools=\"\")\n",
    "\n",
    "    # Add heatmap rectangles\n",
    "    p.rect(x=\"P\", y=\"delta\", width=1, height=1, source=source,\n",
    "        line_color=None, fill_color=transform('log_error', mapper))\n",
    "\n",
    "    log_formatter = CustomJSTickFormatter(code=\"\"\"\n",
    "        return Math.exp(tick).toFixed(1);\n",
    "    \"\"\")\n",
    "    lin_formatter = CustomJSTickFormatter(code=\"\"\"\n",
    "        return tick.toFixed(2);\n",
    "    \"\"\")\n",
    "    formatter = log_formatter if log_transform else lin_formatter\n",
    "\n",
    "    # Add color bar\n",
    "    color_bar = ColorBar(color_mapper=mapper, ticker=BasicTicker(desired_num_ticks=11),\n",
    "                        label_standoff=12, location=(0, 0), \n",
    "                        # formatter=PrintfTickFormatter(format=\"%d%%\"),\n",
    "                        formatter=formatter,\n",
    "                        title=cbar_label\n",
    "                        )\n",
    "    p.add_layout(color_bar, 'right')\n",
    "    hover = HoverTool(\n",
    "        tooltips=[\n",
    "            (\"Percentiles\", \"@P\"),\n",
    "            (\"Exclusion (%)\", \"@delta\"),\n",
    "            (\"Error\", err_label)\n",
    "        ],\n",
    "        mode='mouse'\n",
    "    )\n",
    "\n",
    "    p.add_tools(hover)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f41edb-7a7c-419d-8b71-fe30158822d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compute_sample_relative_error(vals, which_variable='std', log_transform=False)\n",
    "p = plot_rel_error(df, which_variable='std')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac661d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compute_sample_relative_error(vals, which_variable='mean')\n",
    "p = plot_rel_error(df, which_variable='mean')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5cd669-e150-4357-bd6d-e6652d369079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_quantile_std_and_mse_bias(stn, values):\n",
    "    \"\"\"\n",
    "    Compute % relative error in standard deviation and MSE for two quantile sampling strategies:\n",
    "    \n",
    "    - Case A: np.arange(1, 99, 1)\n",
    "    - Case B: [1, 5, 10, 50, 90, 95, 99]\n",
    "\n",
    "    Parameters:\n",
    "        stn (str): station ID\n",
    "        values (array-like): 1D array of numeric values\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            'stn_id': str,\n",
    "            'a_err': float (% rel error in std dev),\n",
    "            'b_err': float,\n",
    "            'a_mse': float (MSE of q_vals_a vs true q_vals),\n",
    "            'b_mse': float,\n",
    "            'sample_std': float,\n",
    "            'std_case_a': float,\n",
    "            'std_case_b': float\n",
    "        }\n",
    "    \"\"\"\n",
    "    values = np.asarray(values)\n",
    "    values = values[~np.isnan(values)]\n",
    "    sample_std = np.std(values)\n",
    "\n",
    "    percentiles_a = np.arange(0, 100, 1)\n",
    "    # percentiles_b = [1, 5, 10, 50, 90, 95, 99]\n",
    "    percentiles_b = [0.1,0.5,1,2,5,10,20, 40, 60, 80, 90, 95, 98, 99, 99.5, 99.9]\n",
    "\n",
    "    # \"Observed\" quantiles\n",
    "    q_vals_a = np.percentile(values, percentiles_a)\n",
    "    q_vals_b = np.percentile(values, percentiles_b)\n",
    "\n",
    "    std_a = np.std(q_vals_a)\n",
    "    std_b = np.std(q_vals_b)\n",
    "\n",
    "    rel_error_a = 100 * (std_a - sample_std) / sample_std\n",
    "    rel_error_b = 100 * (std_b - sample_std) / sample_std\n",
    "\n",
    "    return {\n",
    "        'stn_id': stn,\n",
    "        'a_err': rel_error_a,\n",
    "        'b_err': rel_error_b,\n",
    "        'sample_std': sample_std,\n",
    "        'std_case_a': std_a,\n",
    "        'std_case_b': std_b\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c9e411-dd60-463e-bff9-c0ed187ea052",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "stn_set = [s for s in context.official_ids if s in daymet_concurrent_stations]\n",
    "for stn in stn_set:\n",
    "    target_da= stn_da_dict[stn]\n",
    "    test_data = StationData(context, stn)\n",
    "    \n",
    "    # get the unique UAR values\n",
    "    df =  test_data.stn_df.copy()\n",
    "    vals = df[f'{stn}_uar'].dropna().values\n",
    "    # log_vals = np.log(vals)\n",
    "    # sdf = percentile_spread_convergence(vals)\n",
    "    res = compare_quantile_std_and_mse_bias(stn, vals)\n",
    "    all_results.append(res)\n",
    "    if len(all_results) % 50 == 0:\n",
    "        print(f'{len(all_results)}/{len(stn_set)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806eaa4-2a11-4ac9-a569-d62c8f9a917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_cdf(values):\n",
    "    \"\"\"Compute x and y for plotting empirical CDF.\"\"\"\n",
    "    values = np.sort(values)\n",
    "    n = len(values)\n",
    "    y = np.linspace(0, 1, n, endpoint=False)\n",
    "    return values, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a526a6-95cd-4499-9352-6167cd88cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_errs = pd.DataFrame(all_results)\n",
    "df_errs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6280d7ea-5f39-4400-ad94-8f5919ef810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CDFs\n",
    "x_a, y_a = empirical_cdf(df_errs['a_err'].dropna())\n",
    "x_b, y_b = empirical_cdf(df_errs['b_err'].dropna())\n",
    "\n",
    "# Create Bokeh plot\n",
    "p = figure(\n",
    "    width=600, height=400,\n",
    "    x_axis_label=\"Relative Error (%)\",\n",
    "    y_axis_label=\"Empirical CDF\",\n",
    "    title=\"Empirical CDFs of Quantile-based MSE and Std Dev Errors\"\n",
    ")\n",
    "\n",
    "line_a = p.line(x_a, y_a, line_width=2, color=\"green\", line_dash='dashed', legend_label=\"(Booker & Snelder 2012, 2014)\")\n",
    "line_b = p.line(x_b, y_b, line_width=2, color=\"blue\", legend_label=\"(Castellarin et al. 2007)\")\n",
    "\n",
    "# Optional: fine tune\n",
    "p.legend.location = \"bottom_right\"\n",
    "p.legend.click_policy = \"hide\"\n",
    "p.legend.background_fill_alpha = 0.5\n",
    "p.grid.grid_line_alpha = 0.3\n",
    "p = dpf.format_fig_fonts(p, font_size=14)\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad62c27d-0beb-4769-86a8-0e787c0842f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = df_errs['sample_std'], df_errs['a_err']\n",
    "x2, y2 = df_errs['sample_std'], df_errs['b_err']\n",
    "# x_b, y_b = empirical_cdf(df_errs['b_err'].dropna())\n",
    "\n",
    "# Create Bokeh plot\n",
    "p = figure(\n",
    "    width=600, height=400,\n",
    "    x_axis_label=\"Sample Stdev.\",\n",
    "    y_axis_label=\"Relative Error (%)\",\n",
    "    title=\"\"\n",
    ")\n",
    "\n",
    "p.scatter(x1, y1, line_width=2, color=\"green\", alpha=0.5, size=1.5,\n",
    "                   legend_label=\"(Booker & Snelder 2012, 2014)\")\n",
    "p.scatter(x2, y2, line_width=2, color=\"blue\",  alpha=0.5, size=1.5,\n",
    "                   legend_label=\"(Castellarin et al. 2007)\")\n",
    "\n",
    "# Optional: fine tune\n",
    "p.legend.location = \"top_right\"\n",
    "p.legend.click_policy = \"hide\"\n",
    "p.legend.background_fill_alpha = 0.5\n",
    "p.grid.grid_line_alpha = 0.3\n",
    "p = dpf.format_fig_fonts(p, font_size=14)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8615fee9-ee35-46f7-9a4b-49868c68efcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
